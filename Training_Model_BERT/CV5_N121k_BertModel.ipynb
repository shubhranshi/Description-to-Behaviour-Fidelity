{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CV5_N121k_BertModel.ipynb","provenance":[{"file_id":"1ISF80yBhXJzIVV49HserIcbo0PNBirnh","timestamp":1648796742045},{"file_id":"1NJz3obV9V2WCU3BzGTD1GMpTP27PQ5kl","timestamp":1648736355958},{"file_id":"1Yis-xgminVlBbU7V5I29K-_LAqEpgNEW","timestamp":1648720541719},{"file_id":"1R3tqGxnG1mL8ha0apDU642_K9mFhU-0b","timestamp":1648703583745},{"file_id":"1ZqfRsYFpowfkbcbfoRIWImBZUcaQ5UiT","timestamp":1648652982502},{"file_id":"1xEWTY0zAUwHBkXSxczAe-BLNnfxX7lVr","timestamp":1648642803398},{"file_id":"1DZqEFfXt83vtxdugEl2aEjFoI5egcTx3","timestamp":1648631537829},{"file_id":"1IizGo6c64dhUwdubT2OcIe0bvqc93s4Y","timestamp":1648620398546},{"file_id":"1JnmT_YMQ0GrTHWjPvmCLyjQFntBRG9PU","timestamp":1648613401869},{"file_id":"1wUpgkCh2HV_gOQ098egXxngKQN2zPYKQ","timestamp":1648609585352},{"file_id":"1s5O0jfytzUzdaDiWchYD_m_47WjndgTI","timestamp":1648567104208},{"file_id":"1wo3fAN2MGFJi9C9ilA4xJtMUmevRKlE1","timestamp":1648550068293},{"file_id":"1lRFe-DG-fI47iOno3FLu44YRdSzIn3-T","timestamp":1648048167922},{"file_id":"1lCWfyQq1oSdM1y-SykV9WJOREjDN4LBq","timestamp":1646733508831},{"file_id":"1QMlgPokQAYlAqcMg0hlYgWP2PXQsKw5D","timestamp":1646722078738},{"file_id":"1aD7iJ61ymQUsLIjZM3ukfY1YnilKSVD2","timestamp":1645582335951},{"file_id":"1qloEZd2FMmKiFB7tJK4r3_BEJ5dIyJsE","timestamp":1645172845550}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"3c5099e06401464a8d3145c204e36702":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d79c2d205c634275b26fd2c885a04731","IPY_MODEL_724e76e4f17d46f4baeb67cd8d488dde","IPY_MODEL_32810e22ea0c45efad03b5e6088e05b5"],"layout":"IPY_MODEL_522c983df2bb4509a9bd847c75787850"}},"d79c2d205c634275b26fd2c885a04731":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d964e40839dc42a2ae16e29e6f57f70b","placeholder":"​","style":"IPY_MODEL_dfd51dce70b2427d813bb59a0ce124d0","value":"Downloading: 100%"}},"724e76e4f17d46f4baeb67cd8d488dde":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_63c5cef91a7c4b9a8bf2cf90b352e8e0","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2ddb983d1285499fb8a4b8ca55c209f2","value":231508}},"32810e22ea0c45efad03b5e6088e05b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5127f877e14b45d3b309ee6c66502dc9","placeholder":"​","style":"IPY_MODEL_8288f079de4b4526b0dda8ed6271eb26","value":" 226k/226k [00:00&lt;00:00, 293kB/s]"}},"522c983df2bb4509a9bd847c75787850":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d964e40839dc42a2ae16e29e6f57f70b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfd51dce70b2427d813bb59a0ce124d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"63c5cef91a7c4b9a8bf2cf90b352e8e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ddb983d1285499fb8a4b8ca55c209f2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5127f877e14b45d3b309ee6c66502dc9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8288f079de4b4526b0dda8ed6271eb26":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed197669102448de82ee831a67dd0256":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e7dba8ee01c343579b948af86d9b5929","IPY_MODEL_8ef5034bc6a44230a11f87a27d99b345","IPY_MODEL_2556192672e344f081876048e9e0f2a8"],"layout":"IPY_MODEL_bdac04bb66154fd2a1815557e8861304"}},"e7dba8ee01c343579b948af86d9b5929":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_02695d091db24067bd1c14657a83f42d","placeholder":"​","style":"IPY_MODEL_566591caf22d40f68d1cfe5b2b5b47b8","value":"Downloading: 100%"}},"8ef5034bc6a44230a11f87a27d99b345":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f61164c9f24f415896435e3b59864e9d","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3182da6bc2cc4457b4f678d52d3f9625","value":28}},"2556192672e344f081876048e9e0f2a8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c86ca775d6c465f93f4a5ef3c982398","placeholder":"​","style":"IPY_MODEL_67e382f4c7444cee8cafc6e854198165","value":" 28.0/28.0 [00:00&lt;00:00, 491B/s]"}},"bdac04bb66154fd2a1815557e8861304":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02695d091db24067bd1c14657a83f42d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"566591caf22d40f68d1cfe5b2b5b47b8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f61164c9f24f415896435e3b59864e9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3182da6bc2cc4457b4f678d52d3f9625":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9c86ca775d6c465f93f4a5ef3c982398":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67e382f4c7444cee8cafc6e854198165":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7440400e6e154c0fa026789ccab96144":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1a56c088c6d040079caf0b48c0cd94e0","IPY_MODEL_7d333bec7baf4a93a699e986d7b14861","IPY_MODEL_e587305209bf4cdfbe1a0b4c984b0644"],"layout":"IPY_MODEL_432e79b5dbc84662bd2ae046bc88ca87"}},"1a56c088c6d040079caf0b48c0cd94e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3886a430d952437c82d0ed6368a45f1f","placeholder":"​","style":"IPY_MODEL_5e6c5e92e3de4eff901cd6504fdf5ae0","value":"Downloading: 100%"}},"7d333bec7baf4a93a699e986d7b14861":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_24cbf953eca84aa389d9574f306a4bbb","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0ba1e58fe8b44a86812caa9f0a95d580","value":570}},"e587305209bf4cdfbe1a0b4c984b0644":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_96b303703d1140ef9ed932ba214eec67","placeholder":"​","style":"IPY_MODEL_b2b66aed94e443788324f01b61db48e4","value":" 570/570 [00:00&lt;00:00, 20.2kB/s]"}},"432e79b5dbc84662bd2ae046bc88ca87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3886a430d952437c82d0ed6368a45f1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e6c5e92e3de4eff901cd6504fdf5ae0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24cbf953eca84aa389d9574f306a4bbb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ba1e58fe8b44a86812caa9f0a95d580":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"96b303703d1140ef9ed932ba214eec67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2b66aed94e443788324f01b61db48e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"26f6040e844f485b9013d18c25bb0dba":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9b9ae88070f44da296a8d9480c5e6ff2","IPY_MODEL_0411a548a90a41d79bcbe24e74d93e4f","IPY_MODEL_03cddbebdb404e488e145f32f0d59674"],"layout":"IPY_MODEL_55cdcb6bd2c84a0482784d95631c4ec9"}},"9b9ae88070f44da296a8d9480c5e6ff2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff091bd6eaad46b0ab1cb427e4edd7fa","placeholder":"​","style":"IPY_MODEL_8144e6a99d3e4f2581a02d222e6a868c","value":"Downloading: 100%"}},"0411a548a90a41d79bcbe24e74d93e4f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b011046bc3594f2aba36488b42b85a34","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0874420ecd174d4ebd4be16775e0122f","value":440473133}},"03cddbebdb404e488e145f32f0d59674":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d32a4b03a63b42b9ad9f4f370274f2e9","placeholder":"​","style":"IPY_MODEL_5dfa391ebd4a4a5f80480ed39636a0f7","value":" 420M/420M [00:07&lt;00:00, 63.1MB/s]"}},"55cdcb6bd2c84a0482784d95631c4ec9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff091bd6eaad46b0ab1cb427e4edd7fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8144e6a99d3e4f2581a02d222e6a868c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b011046bc3594f2aba36488b42b85a34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0874420ecd174d4ebd4be16775e0122f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d32a4b03a63b42b9ad9f4f370274f2e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5dfa391ebd4a4a5f80480ed39636a0f7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["Cross Validation 5\n","\n","size = 121655\n","\n","test size 4k+\n","\n","epoch-5\n","\n","apply sigmoid (prediction probabilities are logits)\n","\n","groups-9\n","\n","target_list = ['Camera', 'Location', 'Microphone', 'Contacts', 'Storage', 'Phone', 'SMS', 'Call_Log', 'Calendar']\n","\n","threshold-tuning = yes\n","\n","df_2k = df[(df['Rating'] >= 4.0) & (df['Maximum_Installs'] >= 5000)] \n","\n","accuracy score : F1 score (micro) and ROC_AUC score"],"metadata":{"id":"5aFFg4U_RpMN"}},{"cell_type":"markdown","metadata":{"id":"uUzoYw6RXdak"},"source":["#Part I - Setup and Dataset Prep"]},{"cell_type":"markdown","metadata":{"id":"JMnwDkDvXDzY"},"source":["## 1. Setup"]},{"cell_type":"markdown","metadata":{"id":"cxhWzBwhXHAF"},"source":["### 1.1. Using Colab GPU for Training"]},{"cell_type":"code","metadata":{"id":"U92QfIZnn5FX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b68cdbd6-2e1b-4ddb-830f-7a6b09c513fe","executionInfo":{"status":"ok","timestamp":1648800638798,"user_tz":-480,"elapsed":5552,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"source":["import tensorflow as tf\n","\n","# Get the GPU device name.\n","device_name = tf.test.gpu_device_name()\n","\n","# The device name should look like the following:\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Found GPU at: /device:GPU:0\n"]}]},{"cell_type":"code","source":["print(tf.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8t10Dm2Nu6G0","outputId":"10b598d7-d10e-42e4-9352-1bdb048cb698","executionInfo":{"status":"ok","timestamp":1648800638799,"user_tz":-480,"elapsed":4,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["2.8.0\n"]}]},{"cell_type":"code","metadata":{"id":"MaBsNGImoD6p","colab":{"base_uri":"https://localhost:8080/"},"outputId":"99228edf-64f7-432c-b1bc-b8d5f04d4432","executionInfo":{"status":"ok","timestamp":1648800652195,"user_tz":-480,"elapsed":13399,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"source":["import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla P100-PCIE-16GB\n"]}]},{"cell_type":"markdown","metadata":{"id":"v6TnBQe9X9S7"},"source":["### 1.2. Installing the Hugging Face Library"]},{"cell_type":"markdown","metadata":{"id":"w4Hl-aALYCcv"},"source":["Next, let's install the [transformers](https://github.com/huggingface/transformers) package from Hugging Face which will give us a pytorch interface for working with BERT."]},{"cell_type":"code","metadata":{"id":"MLVkiCBaoD3v","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e98f8b1f-00d4-462d-ed2a-72f41da9dd98","executionInfo":{"status":"ok","timestamp":1648800659627,"user_tz":-480,"elapsed":7437,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"source":["!pip install transformers"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 4.3 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 5.7 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 85.4 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 80.0 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,>=0.11.1\n","  Downloading tokenizers-0.12.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 72.1 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.12.0 transformers-4.17.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"cnwSpHRDYRTj"},"source":["## 2. Retrieve and Inspect Dataset"]},{"cell_type":"markdown","metadata":{"id":"ftKO1mkSYxft"},"source":["### 2.1 Load dataset"]},{"cell_type":"code","metadata":{"id":"5TNLp5X1YMMc","executionInfo":{"status":"ok","timestamp":1648800660204,"user_tz":-480,"elapsed":581,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"source":["## import libraries\n","\n","import itertools\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import pandas as pd\n","import numpy as np\n","\n","from sklearn import preprocessing\n","%matplotlib inline"],"execution_count":5,"outputs":[]},{"cell_type":"code","source":["## uploading csv files on drive (to avoid uploading on colab in every session)\n","\n","from google.colab import drive\n","drive.mount(\"/content/drive/\")\n","\n","## drive path\n","train_path = \"/content/drive/MyDrive/MetadataCSV/data_121655/CV_df_train_5.csv\"\n","val_path = \"/content/drive/MyDrive/MetadataCSV/data_121655/CV_df_val_5.csv\"\n","test_path = \"/content/drive/MyDrive/MetadataCSV/test_dataset.csv\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S_PX7sNK23il","outputId":"57112634-a660-4cd9-e771-8388940a3897","executionInfo":{"status":"ok","timestamp":1648800679215,"user_tz":-480,"elapsed":19013,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","metadata":{"id":"fo13-nGyYMJS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c31cf625-fe80-422b-e186-44be5e39575b","executionInfo":{"status":"ok","timestamp":1648800688452,"user_tz":-480,"elapsed":9240,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"source":["df_train = pd.read_csv(train_path)\n","df_val = pd.read_csv(val_path) \n","df_test = pd.read_csv(test_path)\n","\n","print(df_train.shape)\n","print(df_val.shape)\n","print(df_test.shape)"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["(97324, 23)\n","(24331, 23)\n","(4624, 23)\n"]}]},{"cell_type":"code","source":["df_train.head(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":327},"id":"D30vNXfwVC2N","executionInfo":{"status":"ok","timestamp":1648800688454,"user_tz":-480,"elapsed":17,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}},"outputId":"b6b2fccc-5a88-42b1-dcf9-57e479269077"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                     App_Name                     App_Id       Category  \\\n","0     Scorpion in phone prank  us.funset.scorpioonscreen  Entertainment   \n","1  Daily Connect (Child Care)            com.seacloud.dc      Education   \n","\n","   Rating  Maximum_Installs  Editors_Choice  \\\n","0     4.3             49161           False   \n","1     4.5             57235           False   \n","\n","                                         Description  \\\n","0  Do you want to scare a friend? Put the scorpio...   \n","1  Daily Connect makes it easier than ever to run...   \n","\n","                         Privacy_Policy  Sensors  Camera  ...  Contacts  SMS  \\\n","0            https://justpaste.it/17e7f        0       0  ...         0    0   \n","1  https://www.dailyconnect.com/privacy        0       1  ...         0    0   \n","\n","   Storage  Phone  Get_Accounts  Call_Log  desc_length  \\\n","0        1      0             0         0          663   \n","1        1      0             0         0         3608   \n","\n","                                   Clean_Description  clean_desc_length  \\\n","0  do you want to scare a friend? put the scorpio...                644   \n","1  daily connect makes it easier than ever to run...               3365   \n","\n","   token_length  \n","0           135  \n","1           622  \n","\n","[2 rows x 23 columns]"],"text/html":["\n","  <div id=\"df-d08944fc-3cfc-4c0a-8e4c-7fc8dca85528\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>App_Name</th>\n","      <th>App_Id</th>\n","      <th>Category</th>\n","      <th>Rating</th>\n","      <th>Maximum_Installs</th>\n","      <th>Editors_Choice</th>\n","      <th>Description</th>\n","      <th>Privacy_Policy</th>\n","      <th>Sensors</th>\n","      <th>Camera</th>\n","      <th>...</th>\n","      <th>Contacts</th>\n","      <th>SMS</th>\n","      <th>Storage</th>\n","      <th>Phone</th>\n","      <th>Get_Accounts</th>\n","      <th>Call_Log</th>\n","      <th>desc_length</th>\n","      <th>Clean_Description</th>\n","      <th>clean_desc_length</th>\n","      <th>token_length</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Scorpion in phone prank</td>\n","      <td>us.funset.scorpioonscreen</td>\n","      <td>Entertainment</td>\n","      <td>4.3</td>\n","      <td>49161</td>\n","      <td>False</td>\n","      <td>Do you want to scare a friend? Put the scorpio...</td>\n","      <td>https://justpaste.it/17e7f</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>663</td>\n","      <td>do you want to scare a friend? put the scorpio...</td>\n","      <td>644</td>\n","      <td>135</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Daily Connect (Child Care)</td>\n","      <td>com.seacloud.dc</td>\n","      <td>Education</td>\n","      <td>4.5</td>\n","      <td>57235</td>\n","      <td>False</td>\n","      <td>Daily Connect makes it easier than ever to run...</td>\n","      <td>https://www.dailyconnect.com/privacy</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3608</td>\n","      <td>daily connect makes it easier than ever to run...</td>\n","      <td>3365</td>\n","      <td>622</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2 rows × 23 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d08944fc-3cfc-4c0a-8e4c-7fc8dca85528')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d08944fc-3cfc-4c0a-8e4c-7fc8dca85528 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d08944fc-3cfc-4c0a-8e4c-7fc8dca85528');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"CCOEc0SGQraA","executionInfo":{"status":"ok","timestamp":1648800688455,"user_tz":-480,"elapsed":16,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"source":["target_list = ['Camera', 'Location', 'Microphone', 'Contacts', 'Storage', 'Phone', 'SMS', 'Call_Log', 'Calendar']"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aFU9pOO5QrXA","outputId":"1bb4c968-78a0-47cd-98cc-92d265340bf9","executionInfo":{"status":"ok","timestamp":1648800688455,"user_tz":-480,"elapsed":16,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"source":["# getting number of nonzeros in each column\n","df_train[target_list].astype(bool).sum(axis=0)"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Camera        16414\n","Location      16300\n","Microphone     8907\n","Contacts      10592\n","Storage       48146\n","Phone         15140\n","SMS             344\n","Call_Log        217\n","Calendar       1779\n","dtype: int64"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["df_val[target_list].astype(bool).sum(axis=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eazoqGymZvXv","executionInfo":{"status":"ok","timestamp":1648800688456,"user_tz":-480,"elapsed":14,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}},"outputId":"b91b5d4a-55e8-48d9-954a-8f503e3a98ad"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Camera         4039\n","Location       4042\n","Microphone     2134\n","Contacts       2528\n","Storage       12112\n","Phone          3737\n","SMS              69\n","Call_Log         49\n","Calendar        462\n","dtype: int64"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kMHhiqKdR27G","outputId":"04cc4aa9-d874-4fca-9ffa-65890db970a9","executionInfo":{"status":"ok","timestamp":1648800688457,"user_tz":-480,"elapsed":13,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"source":["df_test[target_list].astype(bool).sum(axis=0)"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Camera         745\n","Location       716\n","Microphone     436\n","Contacts       500\n","Storage       2402\n","Phone          652\n","SMS             11\n","Call_Log         6\n","Calendar        90\n","dtype: int64"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"ayEwDiGzZYvR"},"source":["## 3. BERT Input Length Limitation"]},{"cell_type":"markdown","metadata":{"id":"yvMes-hdZhkA"},"source":["BERT has a maximum input length of 512 tokens. In this section, we'll look at how this limitation affects us in practice, and some possible approaches for addressing it,"]},{"cell_type":"markdown","metadata":{"id":"Sbou1T8raBTJ"},"source":["### 3.1. Examples of 512 Tokens"]},{"cell_type":"markdown","metadata":{"id":"2x8vq5NJaGPg"},"source":["First we'll need to load the BERT tokenizer."]},{"cell_type":"code","metadata":{"id":"IR2azVk_ai8Q","colab":{"base_uri":"https://localhost:8080/","height":130,"referenced_widgets":["3c5099e06401464a8d3145c204e36702","d79c2d205c634275b26fd2c885a04731","724e76e4f17d46f4baeb67cd8d488dde","32810e22ea0c45efad03b5e6088e05b5","522c983df2bb4509a9bd847c75787850","d964e40839dc42a2ae16e29e6f57f70b","dfd51dce70b2427d813bb59a0ce124d0","63c5cef91a7c4b9a8bf2cf90b352e8e0","2ddb983d1285499fb8a4b8ca55c209f2","5127f877e14b45d3b309ee6c66502dc9","8288f079de4b4526b0dda8ed6271eb26","ed197669102448de82ee831a67dd0256","e7dba8ee01c343579b948af86d9b5929","8ef5034bc6a44230a11f87a27d99b345","2556192672e344f081876048e9e0f2a8","bdac04bb66154fd2a1815557e8861304","02695d091db24067bd1c14657a83f42d","566591caf22d40f68d1cfe5b2b5b47b8","f61164c9f24f415896435e3b59864e9d","3182da6bc2cc4457b4f678d52d3f9625","9c86ca775d6c465f93f4a5ef3c982398","67e382f4c7444cee8cafc6e854198165","7440400e6e154c0fa026789ccab96144","1a56c088c6d040079caf0b48c0cd94e0","7d333bec7baf4a93a699e986d7b14861","e587305209bf4cdfbe1a0b4c984b0644","432e79b5dbc84662bd2ae046bc88ca87","3886a430d952437c82d0ed6368a45f1f","5e6c5e92e3de4eff901cd6504fdf5ae0","24cbf953eca84aa389d9574f306a4bbb","0ba1e58fe8b44a86812caa9f0a95d580","96b303703d1140ef9ed932ba214eec67","b2b66aed94e443788324f01b61db48e4"]},"outputId":"eff875cd-f4f8-44e4-e3a7-cb37aef869e9","executionInfo":{"status":"ok","timestamp":1648800695353,"user_tz":-480,"elapsed":6907,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"source":["from transformers import BertTokenizer\n","\n","# Load the BERT tokenizer.\n","print('Loading BERT tokenizer...')\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading BERT tokenizer...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c5099e06401464a8d3145c204e36702"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed197669102448de82ee831a67dd0256"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7440400e6e154c0fa026789ccab96144"}},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"OnJeoNA8ifvA"},"source":["### 3.2. Strategies for longer text"]},{"cell_type":"markdown","metadata":{"id":"5VLifkcRW9L9"},"source":["Paper: How to Fine tune BERT for text classification - visit video :\n","https://www.youtube.com/watch?v=_eSGWNqKeeY&t=1117s\n"," and conference paper https://link.springer.com/chapter/10.1007/978-3-030-32381-3_16 for more details"]},{"cell_type":"markdown","metadata":{"id":"hnB_YRzsd1Zc"},"source":["### 3.3. Comment Length (Description) Distribution"]},{"cell_type":"markdown","metadata":{"id":"qfee8L5id8py"},"source":["To decide on a truncation strategy for this dataset, lets first look at the distribution of the comment lengths.\n","\n","To do this, our first step is to tokenize all of the comments in the training set."]},{"cell_type":"markdown","metadata":{"id":"aglKkuqCeQ7B"},"source":["**Tokenize All Comments**\n","\n","The `tokenizer.encode` function combines multiple steps for us:\n","1. Split the sentence into tokens.\n","2. Add the special `[CLS]` and `[SEP]` tokens.\n","3. Map the tokens to their IDs.\n","\n","In order to explore the distribution of descriptions length, we will not perform any truncation here. Unfortunately, this results in the tokenizer spitting out a warning for every description that's longer than 512 tokens. We'll just have to ignore those for now!"]},{"cell_type":"code","source":[""],"metadata":{"id":"nRwG0VmMQMe4"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"status":"ok","timestamp":1648800696340,"user_tz":-480,"elapsed":989,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}},"colab":{"base_uri":"https://localhost:8080/"},"id":"8IXZaCJViLl4","outputId":"e7118ffe-8162-40b5-9973-44fdf915e47c"},"outputs":[{"output_type":"stream","name":"stdout","text":["(1417, 14)\n"]}],"source":["## drive path\n","acnet_path = \"/content/drive/MyDrive/MetadataCSV/acnet_dataset_preprocess.csv\"\n","\n","df_acnet = pd.read_csv(acnet_path) \n","print(df_acnet.shape)"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"status":"ok","timestamp":1648800696341,"user_tz":-480,"elapsed":8,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}},"colab":{"base_uri":"https://localhost:8080/"},"id":"wiPaC0FqiLl5","outputId":"730cb7fc-dec2-445c-9c74-3126565319f0"},"outputs":[{"output_type":"stream","name":"stdout","text":["(1414, 14)\n"]}],"source":["df_acnet = df_acnet.dropna(subset=['Clean_Description'])\n","print(df_acnet.shape)"]},{"cell_type":"code","source":["train_clean_description = df_train.Clean_Description\n","#print(train_clean_description)"],"metadata":{"id":"VQ4YUk2shoCq","executionInfo":{"status":"ok","timestamp":1648800696341,"user_tz":-480,"elapsed":5,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["train_clean_description = train_clean_description.append(df_acnet.Clean_Description)\n","#print(train_clean_description)"],"metadata":{"id":"ZLvFIX_hpDTR","executionInfo":{"status":"ok","timestamp":1648800696341,"user_tz":-480,"elapsed":5,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"r78Ij0ftQWbq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","# Tokenize all of the sentences and map the tokens to thier word IDs.\n","train_input_ids = []\n","\n","# Record the length of each sequence (after truncating to 512)\n","train_lengths = []\n","\n","print('Tokenizing descriptions...')\n","\n","# For every sentence...\n","for sent in train_clean_description:  #df_train.Clean_Description:\n","\n","    # Report progress\n","    if ((len(train_input_ids) % 20000) == 0):\n","        print('   Read {:,} descriptions.'.format(len(train_input_ids)))\n","\n","    # `encode` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    encoded_sent = tokenizer.encode(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        #max_length = 128,          # Truncate all sentences.\n","                        #return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.\n","    train_input_ids.append(encoded_sent)\n","\n","    # Record the truncated length.\n","    train_lengths.append(len(encoded_sent))\n","\n","print('DONE. ')\n","print('{:>10,} comments'.format(len(train_input_ids)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g03BEVQ5BEDX","outputId":"a927e63d-00d7-4e4e-e72f-de7b16efa206","executionInfo":{"status":"ok","timestamp":1648801253771,"user_tz":-480,"elapsed":557435,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (622 > 512). Running this sequence through the model will result in indexing errors\n"]},{"output_type":"stream","name":"stdout","text":["Tokenizing descriptions...\n","   Read 0 descriptions.\n","   Read 20,000 descriptions.\n","   Read 40,000 descriptions.\n","   Read 60,000 descriptions.\n","   Read 80,000 descriptions.\n","DONE. \n","    98,738 comments\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","# Tokenize all of the sentences and map the tokens to thier word IDs.\n","val_input_ids = []\n","\n","# Record the length of each sequence (after truncating to 512)\n","val_lengths = []\n","\n","print('Tokenizing descriptions...')\n","\n","# For every sentence...\n","for sent in df_val.Clean_Description:\n","\n","    # Report progress\n","    if ((len(val_input_ids) % 20000) == 0):\n","        print('   Read {:,} descriptions.'.format(len(val_input_ids)))\n","\n","    # `encode` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    encoded_sent = tokenizer.encode(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        #max_length = 128,          # Truncate all sentences.\n","                        #return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.\n","    val_input_ids.append(encoded_sent)\n","\n","    # Record the truncated length.\n","    val_lengths.append(len(encoded_sent))\n","\n","print('DONE. ')\n","print('{:>10,} comments'.format(len(val_input_ids)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FmAzdfXWaLLF","executionInfo":{"status":"ok","timestamp":1648801389999,"user_tz":-480,"elapsed":136239,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}},"outputId":"2d2288a0-9498-4118-b62d-abf97c2da7bc"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenizing descriptions...\n","   Read 0 descriptions.\n","   Read 20,000 descriptions.\n","DONE. \n","    24,331 comments\n"]}]},{"cell_type":"code","metadata":{"id":"FqV2aTwne_tE","executionInfo":{"status":"ok","timestamp":1648801389999,"user_tz":-480,"elapsed":11,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"source":["# Also retrieve the labels as a list\n","\n","train_labels = df_train[target_list]\n","train_labels = train_labels.append(df_acnet[target_list])\n","\n","validation_labels = df_val[target_list]"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KtnVh5-MBNGA"},"source":["### 3.4. Pad & Truncate Comments"]},{"cell_type":"markdown","metadata":{"id":"yArLr5cwBmIo"},"source":["Truncate the descriptions to 512 tokens.\n","\n","Not only that, but i think we can get away with an even shorter sequence length to speed things up. I have picked up a max length of 128, since this is around the \"elbow\" of the distribution.\n","\n","We can always try longer lengths later to see how much this will omprove our result."]},{"cell_type":"code","metadata":{"id":"-5eFTly2BUB2","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7ca25f1b-449e-4631-afb6-4df7c28a954b","executionInfo":{"status":"ok","timestamp":1648801391534,"user_tz":-480,"elapsed":1545,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"source":["# We'll borrow the `pad_sequence` utility function to do this.\n","\n","from keras.preprocessing.sequence import pad_sequences\n","\n","#Set the required sentence length\n","MAX_LEN = 256   #128\n","\n","print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n","\n","print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n","\n","# Pad our input tokens with value 0.\n","train_inputs = pad_sequences(train_input_ids, maxlen=MAX_LEN, dtype=\"long\", \n","                          value=0, truncating=\"post\", padding=\"post\")\n","\n","validation_inputs = pad_sequences(val_input_ids, maxlen=MAX_LEN, dtype=\"long\", \n","                          value=0, truncating=\"post\", padding=\"post\")\n","\n","print('\\nDone.')"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Padding/truncating all sentences to 256 values...\n","\n","Padding token: \"[PAD]\", ID: 0\n","\n","Done.\n"]}]},{"cell_type":"markdown","metadata":{"id":"0HDf7fiGDMsY"},"source":["**Attention Masks**"]},{"cell_type":"markdown","metadata":{"id":"X9pOa0hpDQuV"},"source":["The attention mask simply makes it explicit which tokens are actual words versus which are padding.\n","\n","The BERT vocabulary does not use the ID 0, so if a token ID is 0, then it's padding, and otherwise it's a real token. "]},{"cell_type":"code","metadata":{"id":"1Ah2gRMuBTy0","executionInfo":{"status":"ok","timestamp":1648801401992,"user_tz":-480,"elapsed":10460,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"source":["# Create attention masks\n","train_masks = []\n","\n","# For each sentence...\n","for sent in train_inputs:\n","    \n","    # Create the attention mask.\n","    #   - If a token ID is 0, then it's padding, set the mask to 0.\n","    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n","    att_mask = [int(token_id > 0) for token_id in sent]\n","    \n","    # Store the attention mask for this sentence.\n","    train_masks.append(att_mask)"],"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# Create attention masks\n","validation_masks = []\n","\n","# For each sentence...\n","for sent in validation_inputs:\n","    \n","    # Create the attention mask.\n","    #   - If a token ID is 0, then it's padding, set the mask to 0.\n","    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n","    att_mask = [int(token_id > 0) for token_id in sent]\n","    \n","    # Store the attention mask for this sentence.\n","    validation_masks.append(att_mask)"],"metadata":{"id":"YGNlnxkmicYn","executionInfo":{"status":"ok","timestamp":1648801405205,"user_tz":-480,"elapsed":3222,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j_eothNuoEqJ"},"source":["### 3.5. Final Data Prep"]},{"cell_type":"code","source":["### my code ---start\n","\n","import pandas as pd\n","\n","train_labels = train_labels.to_numpy()\n","validation_labels = validation_labels.to_numpy()\n","\n","## my code ---end"],"metadata":{"id":"o40DaKEvmjpa","executionInfo":{"status":"ok","timestamp":1648801405206,"user_tz":-480,"elapsed":3,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CT8SvIzOoc4u"},"source":["2. Our model expects PyTorch tensors rather than numpy.ndarrays, so convert all of our dataset variables."]},{"cell_type":"code","metadata":{"id":"y-8RXqHwoD09","executionInfo":{"status":"ok","timestamp":1648801408190,"user_tz":-480,"elapsed":2986,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"source":["# Convert all inputs and labels into torch tensors, the required datatype \n","# for our model.\n","train_inputs = torch.tensor(train_inputs)\n","validation_inputs = torch.tensor(validation_inputs)\n","\n","train_labels = torch.FloatTensor(train_labels)\n","validation_labels = torch.FloatTensor(validation_labels)\n","\n","train_masks = torch.tensor(train_masks)\n","validation_masks = torch.tensor(validation_masks)"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"njILqZc8o-M5"},"source":["3. We'll also create an iterator for our dataset using the torch DataLoader class. This helps save on memory during training because, unlike a for loop, with an iterator the entire dataset does not need to be loaded into memory."]},{"cell_type":"code","metadata":{"id":"cpd2KwEAoDxz","executionInfo":{"status":"ok","timestamp":1648801408190,"user_tz":-480,"elapsed":10,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","# The DataLoader needs to know our batch size for training, so we specify it \n","# here.\n","# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n","# 16 or 32.\n","\n","batch_size = 16 #32\n","\n","# Create the DataLoader for our training set.\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","# Create the DataLoader for our validation set.\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"noQqIAKxpeW1"},"source":["#Part II - BERT Fine-Tuning"]},{"cell_type":"markdown","metadata":{"id":"ynXgv5AWpq48"},"source":["##4. Train our classification Model"]},{"cell_type":"markdown","metadata":{"id":"-IPsyl-6py0H"},"source":["Now that our input data is properly formatted, it's time to fine tune the BERT model."]},{"cell_type":"markdown","metadata":{"id":"cBabGbjrrP3-"},"source":["###4.1. BertForSequenceClassification"]},{"cell_type":"markdown","metadata":{"id":"wMMqQLRBp2iH"},"source":["\n","**BertForSequenceClassification** - The one we'll use.\n"]},{"cell_type":"code","metadata":{"id":"hZR7gbo6oDup","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["26f6040e844f485b9013d18c25bb0dba","9b9ae88070f44da296a8d9480c5e6ff2","0411a548a90a41d79bcbe24e74d93e4f","03cddbebdb404e488e145f32f0d59674","55cdcb6bd2c84a0482784d95631c4ec9","ff091bd6eaad46b0ab1cb427e4edd7fa","8144e6a99d3e4f2581a02d222e6a868c","b011046bc3594f2aba36488b42b85a34","0874420ecd174d4ebd4be16775e0122f","d32a4b03a63b42b9ad9f4f370274f2e9","5dfa391ebd4a4a5f80480ed39636a0f7"]},"outputId":"02d5de3d-ffaf-43c2-8da5-f263dd9c71a4","executionInfo":{"status":"ok","timestamp":1648801418476,"user_tz":-480,"elapsed":10295,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"source":["from transformers import BertForSequenceClassification, AdamW, BertConfig\n","\n","# Load BertForSequenceClassification, the pretrained BERT model with a single \n","# linear classification layer on top. \n","model = BertForSequenceClassification.from_pretrained(\n","    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n","    problem_type = \"multi_label_classification\",\n","    num_labels = 9, # The number of output labels--2 for binary classification.\n","                    # You can increase this for multi-class tasks. IN OUR CASE - 9  ....6 \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n",")\n","\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()"],"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26f6040e844f485b9013d18c25bb0dba"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",")"]},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"6K-112u1rJgm"},"source":["###4.2. Optimizer & Learning Rate Scheduler"]},{"cell_type":"code","metadata":{"id":"6-wjNOjWoDrv","executionInfo":{"status":"ok","timestamp":1648801418476,"user_tz":-480,"elapsed":12,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b025d250-515d-4549-c24e-618b64b5ecb8"},"source":["# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n","# I believe the 'W' stands for 'Weight Decay fix\"\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )"],"execution_count":28,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]}]},{"cell_type":"code","metadata":{"id":"Zqu3bS1PoDpF","executionInfo":{"status":"ok","timestamp":1648801418477,"user_tz":-480,"elapsed":12,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"source":["from transformers import get_linear_schedule_with_warmup\n","\n","# Number of training epochs (authors recommend between 2 and 4)\n","epochs = 5\n","\n","# Total number of training steps is number of batches * number of epochs.\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kj6O1EQur9Ue"},"source":["###4.3. Training Loop"]},{"cell_type":"markdown","metadata":{"id":"xASfADMDsRuJ"},"source":["In each pass, we will train the model on our full training set, and then measure its accuracy on our 10% holdout validation set."]},{"cell_type":"markdown","metadata":{"id":"gX3JD3J8shCK"},"source":["Define a helper function for calculating accuracy."]},{"cell_type":"code","source":["# Function to calculate the accuracy of our predictions vs labels\n","\n","import numpy as np\n","from sklearn.metrics import f1_score\n","\n","def flat_accuracy(preds, labels):\n","    #print('my_print_2')\n","    acc = [0, 0 ,0 ,0 ,0 ,0, 0, 0, 0]\n","    preds_th = preds\n","    \n","    preds_th[:, 0] = np.array(preds[:, 0]) >= 0.5\n","    preds_th[:, 1] = np.array(preds[:, 1]) >= 0.5\n","    preds_th[:, 2] = np.array(preds[:, 2]) >= 0.5\n","    preds_th[:, 3] = np.array(preds[:, 3]) >= 0.5\n","    preds_th[:, 4] = np.array(preds[:, 4]) >= 0.5\n","    preds_th[:, 5] = np.array(preds[:, 5]) >= 0.5\n","    preds_th[:, 6] = np.array(preds[:, 6]) >= 0.5\n","    preds_th[:, 7] = np.array(preds[:, 7]) >= 0.5\n","    preds_th[:, 8] = np.array(preds[:, 8]) >= 0.5\n","\n","    acc[0] = f1_score(labels[:, 0], preds_th[:, 0])\n","    acc[1] = f1_score(labels[:, 1], preds_th[:, 1])\n","    acc[2] = f1_score(labels[:, 2], preds_th[:, 2])\n","    acc[3] = f1_score(labels[:, 3], preds_th[:, 3])\n","    acc[4] = f1_score(labels[:, 4], preds_th[:, 4])\n","    acc[5] = f1_score(labels[:, 5], preds_th[:, 5])\n","    acc[6] = f1_score(labels[:, 6], preds_th[:, 6])\n","    acc[7] = f1_score(labels[:, 7], preds_th[:, 7])\n","    acc[8] = f1_score(labels[:, 8], preds_th[:, 8])\n","\n","   #f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n","\n","    #print(acc)\n","    return acc"],"metadata":{"id":"IfVCyHOJ1ix9","executionInfo":{"status":"ok","timestamp":1648801460743,"user_tz":-480,"elapsed":533,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VfBjZjPl_KHt"},"source":["Helper function for formatting elapsed times."]},{"cell_type":"code","metadata":{"id":"x56tp8AIoDmD","executionInfo":{"status":"ok","timestamp":1648801466541,"user_tz":-480,"elapsed":425,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))\n"],"execution_count":31,"outputs":[]},{"cell_type":"code","source":["# Function for class weights\n","\n","import numpy as np\n","from sklearn.utils.class_weight import compute_class_weight\n","from sklearn.preprocessing import MultiLabelBinarizer\n","\n","\n","def generate_class_weights(class_series, multi_class=True, one_hot_encoded=False):\n","  \"\"\"\n","  Method to generate class weights given a set of multi-class or multi-label labels, both one-hot-encoded or not.\n","  Some examples of different formats of class_series and their outputs are:\n","    - generate_class_weights(['mango', 'lemon', 'banana', 'mango'], multi_class=True, one_hot_encoded=False)\n","    {'banana': 1.3333333333333333, 'lemon': 1.3333333333333333, 'mango': 0.6666666666666666}\n","    - generate_class_weights([[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0]], multi_class=True, one_hot_encoded=True)\n","    {0: 0.6666666666666666, 1: 1.3333333333333333, 2: 1.3333333333333333}\n","    - generate_class_weights([['mango', 'lemon'], ['mango'], ['lemon', 'banana'], ['lemon']], multi_class=False, one_hot_encoded=False)\n","    {'banana': 1.3333333333333333, 'lemon': 0.4444444444444444, 'mango': 0.6666666666666666}\n","    - generate_class_weights([[0, 1, 1], [0, 0, 1], [1, 1, 0], [0, 1, 0]], multi_class=False, one_hot_encoded=True)\n","    {0: 1.3333333333333333, 1: 0.4444444444444444, 2: 0.6666666666666666}\n","  The output is a dictionary in the format { class_label: class_weight }. In case the input is one hot encoded, the class_label would be index\n","  of appareance of the label when the dataset was processed. \n","  In multi_class this is np.unique(class_series) and in multi-label np.unique(np.concatenate(class_series)).\n","  Author: Angel Igareta (angel@igareta.com)\n","  \"\"\"\n","  if multi_class:\n","    # If class is one hot encoded, transform to categorical labels to use compute_class_weight   \n","    if one_hot_encoded:\n","      class_series = np.argmax(class_series, axis=1)\n","  \n","    # Compute class weights with sklearn method\n","    class_labels = np.unique(class_series)\n","    class_weights = compute_class_weight(class_weight='balanced', classes=class_labels, y=class_series)\n","\n","    print(class_series)\n","    print(class_labels)\n","\n","    return dict(zip(class_labels, class_weights))\n","  else:\n","    # It is neccessary that the multi-label values are one-hot encoded\n","    mlb = None\n","    if not one_hot_encoded:\n","      mlb = MultiLabelBinarizer()\n","      class_series = mlb.fit_transform(class_series)\n","\n","    n_samples = len(class_series)\n","    n_classes = len(class_series[0])\n","    print(n_samples)\n","    print(n_classes)\n","\n","    # Count each class frequency\n","    class_count = [0] * n_classes\n","    for classes in class_series:\n","        for index in range(n_classes):\n","            if classes[index] != 0:\n","                class_count[index] += 1\n","    \n","    # Compute class weights using balanced method\n","    class_weights = [n_samples / (n_classes * freq) if freq > 0 else 1 for freq in class_count]\n","    class_labels = range(len(class_weights)) if mlb is None else mlb.classes_\n","    #return dict(zip(class_labels, class_weights))\n","    return class_weights"],"metadata":{"id":"wjVzDd1UEnf0","executionInfo":{"status":"ok","timestamp":1648801467712,"user_tz":-480,"elapsed":407,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["class_series = np.array(train_labels)\n","class_wt = generate_class_weights(class_series, multi_class=False, one_hot_encoded=True)\n","print(class_wt)\n","class_wt = torch.tensor(class_wt)\n","print(class_wt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4kmWrszsGk-J","outputId":"8a5cf679-d5b1-4660-dc3b-fb2c81c08dd5","executionInfo":{"status":"ok","timestamp":1648801469135,"user_tz":-480,"elapsed":1427,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["98738\n","9\n","[0.6591893822561371, 0.6607377071120747, 1.2115835327320694, 0.9949114799028647, 0.22516858339775647, 0.71921390382122, 19.73181454836131, 35.050763223287184, 5.826281937806101]\n","tensor([ 0.6592,  0.6607,  1.2116,  0.9949,  0.2252,  0.7192, 19.7318, 35.0508,\n","         5.8263])\n"]}]},{"cell_type":"code","metadata":{"id":"LONVx8d4we9I","executionInfo":{"status":"ok","timestamp":1648801469135,"user_tz":-480,"elapsed":2,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"source":["## Loss function with weights\n","\n","def loss_fn(outputs, targets):\n","    return torch.nn.BCEWithLogitsLoss(pos_weight=class_wt)(outputs, targets)"],"execution_count":34,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"48buXCcF_RFb"},"source":["We're ready to kick off the training!"]},{"cell_type":"code","metadata":{"id":"fyZvsuYfoDjF","colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1I8rYhaEBSeT-Prkk4BYpPbZ0_KKHohEn"},"outputId":"f5047b11-2e5b-4e52-c605-d33392fc1c74","executionInfo":{"status":"ok","timestamp":1648815185933,"user_tz":-480,"elapsed":13712796,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"source":["import random\n","\n","# This training code is based on the `run_glue.py` script here:\n","# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n","\n","\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# Store the average loss after each epoch so we can plot them.\n","loss_values = []\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_loss = 0\n","\n","    # Put the model into training mode. Don't be mislead--the call to \n","    # `train` just changes the *mode*, it doesn't *perform* the training.\n","    # `dropout` and `batchnorm` layers behave differently during training\n","    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 100 batches.\n","        if step % 100 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n","        # `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        #mycode-start\n","        class_wt = class_wt.to(device)\n","        #mycode-end\n","\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass. PyTorch doesn't do this automatically because \n","        # accumulating the gradients is \"convenient while training RNNs\". \n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        # This will return the loss (rather than the model output) because we\n","        # have provided the `labels`.\n","        # The documentation for this `model` function is here: \n","        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","        \n","        outputs = model(b_input_ids, \n","                    token_type_ids=None, \n","                    attention_mask=b_input_mask)  \n","               #     labels=b_labels)\n","\n","        ##mycode----start        \n","        optimizer.zero_grad()\n","        #print(outputs[0])\n","        #print(b_labels)\n","        loss = loss_fn(outputs[0], b_labels)\n","        optimizer.zero_grad()\n","        ##mycode----end\n","\n","        # The call to `model` always returns a tuple, so we need to pull the \n","        # loss value out of the tuple.\n","        #loss = outputs[0]\n","\n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. `loss` is a Tensor containing a\n","        # single value; the `.item()` function just returns the Python value \n","        # from the tensor.\n","        total_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        # The optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over the training data.\n","    avg_train_loss = total_loss / len(train_dataloader)            \n","    \n","    # Store the loss value for plotting the learning curve.\n","    loss_values.append(avg_train_loss)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","\n","    # Tracking variables \n","    eval_loss = 0\n","    eval_accuracy = [0,0,0,0,0,0,0,0,0]\n","    tmp_eval_accuracy = [0,0,0,0,0,0,0,0,0]\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        \n","        # Add batch to GPU\n","        batch = tuple(t.to(device) for t in batch)\n","        \n","        # Unpack the inputs from our dataloader\n","        b_input_ids, b_input_mask, b_labels = batch\n","        \n","        # Telling the model not to compute or store gradients, saving memory and\n","        # speeding up validation\n","        with torch.no_grad():        \n","\n","            # Forward pass, calculate logit predictions.\n","            # This will return the logits rather than the loss because we have\n","            # not provided labels.\n","            # token_type_ids is the same as the \"segment ids\", which \n","            # differentiates sentence 1 and 2 in 2-sentence tasks.\n","            # The documentation for this `model` function is here: \n","            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","            outputs = model(b_input_ids, \n","                            token_type_ids=None, \n","                            attention_mask=b_input_mask)\n","        \n","        # Get the \"logits\" output by the model. The \"logits\" are the output\n","        # values prior to applying an activation function like the softmax.\n","        logits = outputs[0]\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        \n","        # Calculate the accuracy for this batch of test sentences.\n","        #print('my_print_1')\n","        #print(logits)\n","        #print(label_ids)\n","        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","        #print('my_print_3')\n","        #print(tmp_eval_accuracy)\n","        \n","        # Accumulate the total accuracy.\n","        eval_accuracy[0] += tmp_eval_accuracy[0]\n","        eval_accuracy[1] += tmp_eval_accuracy[1]\n","        eval_accuracy[2] += tmp_eval_accuracy[2]\n","        eval_accuracy[3] += tmp_eval_accuracy[3]\n","        eval_accuracy[4] += tmp_eval_accuracy[4]\n","        eval_accuracy[5] += tmp_eval_accuracy[5]\n","        eval_accuracy[6] += tmp_eval_accuracy[6]\n","        eval_accuracy[7] += tmp_eval_accuracy[7]\n","        eval_accuracy[8] += tmp_eval_accuracy[8]\n","        \n","\n","        # Track the number of batches\n","        nb_eval_steps += 1\n","\n","    # Report the final accuracy for this validation run.\n","    print(\"  Accuracy 0: {0:.2f}\".format(eval_accuracy[0]/nb_eval_steps))\n","    print(\"  Accuracy 1: {0:.2f}\".format(eval_accuracy[1]/nb_eval_steps))\n","    print(\"  Accuracy 2: {0:.2f}\".format(eval_accuracy[2]/nb_eval_steps))\n","    print(\"  Accuracy 3: {0:.2f}\".format(eval_accuracy[3]/nb_eval_steps))\n","    print(\"  Accuracy 4: {0:.2f}\".format(eval_accuracy[4]/nb_eval_steps))\n","    print(\"  Accuracy 5: {0:.2f}\".format(eval_accuracy[5]/nb_eval_steps))\n","    print(\"  Accuracy 6: {0:.2f}\".format(eval_accuracy[6]/nb_eval_steps))\n","    print(\"  Accuracy 7: {0:.2f}\".format(eval_accuracy[7]/nb_eval_steps))\n","    print(\"  Accuracy 8: {0:.2f}\".format(eval_accuracy[8]/nb_eval_steps))\n","\n","\n","    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n","\n","print(\"\")\n","print(\"Training complete!\")"],"execution_count":35,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"lfqAcBnMAlSb"},"source":["Let's take a look at our training loss over all batches:"]},{"cell_type":"code","metadata":{"id":"bO-u38yVoDgP","executionInfo":{"status":"ok","timestamp":1648816717144,"user_tz":-480,"elapsed":691,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}},"colab":{"base_uri":"https://localhost:8080/","height":427},"outputId":"8eee3f33-3eab-4613-ac4c-36c805ec17d7"},"source":["import matplotlib.pyplot as plt\n","% matplotlib inline\n","\n","import seaborn as sns\n","\n","# Use plot styling from seaborn.\n","sns.set(style='darkgrid')\n","\n","# Increase the plot size and font size.\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","# Plot the learning curve.\n","plt.plot(loss_values, 'b-o')\n","\n","# Label the plot.\n","plt.title(\"Training loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","\n","plt.show()"],"execution_count":36,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 864x432 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"R5wjgyY0A0vM"},"source":["## 5. Performance On Test Set"]},{"cell_type":"markdown","metadata":{"id":"W5DgsR5qA7JN"},"source":["Now we'll load the holdout dataset and prepare inputs just as we did with the training set."]},{"cell_type":"markdown","metadata":{"id":"t0bfyzT2LJ3U"},"source":["### 5.1. Data Preparation"]},{"cell_type":"markdown","metadata":{"id":"Tl9lNExlLNgJ"},"source":["We'll need to apply all of the same steps that we did for the training data to prepare our test data set."]},{"cell_type":"code","metadata":{"id":"Gf7qG_QAoDdO","executionInfo":{"status":"ok","timestamp":1648816853469,"user_tz":-480,"elapsed":34717,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b98cc5ee-d7de-44f3-e310-0d5e681378f1"},"source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","test_input_ids = []\n","\n","# For every sentence...\n","for sent in df_test.Clean_Description:\n","\n","    # Report the number of sentences.\n","    if((len(test_input_ids) % 20000) == 0):\n","        print(' Read {:,} comments'.format(len(test_input_ids)))\n","\n","    # `encode` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    encoded_sent = tokenizer.encode(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = MAX_LEN,       # Truncate all sentences.\n","                   )\n","    \n","    # Add the encoded sentence to the list\n","    test_input_ids.append(encoded_sent)\n","\n","print('DONE.')\n","print('')\n","print('{:>10,} test comments'.format(len(test_input_ids)))\n","\n","# Also retrieve the labels as a list.\n","\n","# Get the labels from the dataframe, and convert from booleans to ints\n","test_labels = df_test[target_list]\n","\n","#print('{:>10,} positive (contains attack)'.format(np.sum(test_labels)))\n","#print('{:>10,} negetive (not an attack)'.format(len(test_labels) - np.sum(test_labels)))\n","\n","# Pad our input tokens\n","test_input_ids = pad_sequences(test_input_ids, maxlen=MAX_LEN, \n","                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","# Create attention masks\n","test_attention_masks = []\n","\n","# Create a mask of 1s for each token followed by 0s for padding\n","for seq in test_input_ids:\n","  seq_mask = [float(i>0) for i in seq]\n","  test_attention_masks.append(seq_mask) \n","\n","##my_code_start\n","test_labels = test_labels.to_numpy()\n","##my_code_ends\n","\n","# Convert to tensors.\n","test_inputs = torch.tensor(test_input_ids)\n","test_masks = torch.tensor(test_attention_masks)\n","test_labels = torch.tensor(test_labels)\n","\n","# Set the batch size.  \n","batch_size = 32  \n","\n","# Create the DataLoader.\n","test_data = TensorDataset(test_inputs, test_masks, test_labels)\n","test_sampler = SequentialSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"],"execution_count":37,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":[" Read 0 comments\n","DONE.\n","\n","     4,624 test comments\n"]}]},{"cell_type":"markdown","metadata":{"id":"cSnaxKuMO_tF"},"source":["### 5.2. Evaluate on Test Set"]},{"cell_type":"markdown","metadata":{"id":"12IlPTB4PC94"},"source":["With the test set prepared, we can apply our fine-tuned model to generate predictions on the test set."]},{"cell_type":"code","metadata":{"id":"5jTi6th7oDaT","executionInfo":{"status":"ok","timestamp":1648816890878,"user_tz":-480,"elapsed":37412,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"73861f94-97d7-4b12-c79c-180058d39c18"},"source":["# Prediction on test set\n","\n","print('Predicting labels for {:,} test sentences...'.format(len(test_inputs)))\n","\n","# Put model in evaluation mode\n","model.eval()\n","\n","# Tracking variables \n","predictions , true_labels = [], []\n","\n","# Measure elapsed time.\n","t0 = time.time()\n","\n","# Predict \n","for (step,batch) in enumerate(test_dataloader):\n","  # Add batch to GPU\n","  batch = tuple(t.to(device) for t in batch)\n","  \n","  #Progress update every 100 batches.\n","  if step % 100 == 0 and not step == 0:\n","      # Calculate elapsed time in minutes\n","      elapsed = format_time(time.time() - t0)\n","\n","      # Report progress.\n","      print('  Batch {:>5,} of {:>5,}. Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n","\n","\n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask, b_labels = batch\n","  \n","  # Telling the model not to compute or store gradients, saving memory and \n","  # speeding up prediction\n","  with torch.no_grad():\n","      # Forward pass, calculate logit predictions\n","      outputs = model(b_input_ids, token_type_ids=None, \n","                      attention_mask=b_input_mask)\n","\n","  logits = outputs[0]\n","\n","  # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","  \n","  # Store predictions and true labels\n","  predictions.append(logits)\n","  true_labels.append(label_ids)\n","\n","print('    DONE.')"],"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicting labels for 4,624 test sentences...\n","  Batch   100 of   145. Elapsed: 0:00:26.\n","    DONE.\n"]}]},{"cell_type":"code","metadata":{"id":"qH719j6IoDXX","executionInfo":{"status":"ok","timestamp":1648816890879,"user_tz":-480,"elapsed":26,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"source":["# Combine the results across the batches.\n","predictions = np.concatenate(predictions, axis=0)\n","true_labels = np.concatenate(true_labels, axis=0)"],"execution_count":39,"outputs":[]},{"cell_type":"code","source":["tensor_predictions = torch.tensor(predictions)"],"metadata":{"id":"x_OHvjL9QuBz","executionInfo":{"status":"ok","timestamp":1648816890879,"user_tz":-480,"elapsed":26,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["final_predictions = torch.sigmoid(tensor_predictions)"],"metadata":{"id":"ondzvWz8Vsig","executionInfo":{"status":"ok","timestamp":1648816890879,"user_tz":-480,"elapsed":25,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"execution_count":41,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gSZMT_EmQ2tM"},"source":["Let's peek at the model's output for the first 10 test samples, along with the correct label for each."]},{"cell_type":"code","metadata":{"id":"Q9pZeOEgoDUR","executionInfo":{"status":"ok","timestamp":1648816890880,"user_tz":-480,"elapsed":26,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fea6bc92-63aa-4f0c-90b4-93f87713c75e"},"source":["predictions[0:10]"],"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ -7.0984488 ,  -4.4823265 ,  -7.169     ,  -6.182142  ,\n","         -3.642083  ,  -5.671297  ,  -8.680239  ,  -8.934834  ,\n","         -7.307154  ],\n","       [ -6.0314794 ,  -6.0876293 ,  -5.463483  ,  -5.209831  ,\n","         -2.2600024 ,  -4.3155174 ,  -9.831501  ,  -9.416832  ,\n","         -7.8166437 ],\n","       [ -2.2709908 ,  -3.242055  ,  -1.9721485 ,  -4.398843  ,\n","         -0.67177624,  -1.6228446 , -10.670877  ,  -8.981882  ,\n","         -6.068442  ],\n","       [ -5.620715  ,  -4.9327965 ,  -7.035942  ,  -4.3299594 ,\n","         -2.2475972 ,  -3.1505532 ,  -9.511608  ,  -9.205423  ,\n","         -8.135096  ],\n","       [ -0.8984587 ,  -2.8311834 ,  -5.875697  ,  -3.6274915 ,\n","         -2.665744  ,  -0.1281601 ,  -7.813919  ,  -7.326361  ,\n","         -6.8042274 ],\n","       [ -1.6000025 ,  -2.6199174 ,  -4.39082   ,  -1.8631294 ,\n","         -0.7253746 ,  -2.3748736 ,  -9.074131  ,  -8.995613  ,\n","         -7.6987243 ],\n","       [ -0.2230483 ,  -0.33675432,   5.227593  ,   3.6333797 ,\n","          1.032923  ,   3.8360353 ,  -5.3287196 ,  -3.6946077 ,\n","         -4.5188203 ],\n","       [ -2.8423355 ,  -4.789911  ,  -4.6718545 ,  -4.15281   ,\n","         -3.255081  ,  -3.5368981 ,  -8.489585  ,  -8.6355915 ,\n","         -6.6582847 ],\n","       [ -5.6970115 ,  -4.122221  ,  -6.519385  ,  -5.780043  ,\n","         -2.8989286 ,  -4.181361  ,  -9.852327  ,  -9.772034  ,\n","         -8.333313  ],\n","       [ -3.923939  ,  -2.6398418 ,  -3.029838  ,  -1.040806  ,\n","          1.9431822 ,   0.24083969,  -8.201432  ,  -8.303837  ,\n","         -8.166969  ]], dtype=float32)"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["final_predictions[0:10]"],"metadata":{"id":"EhF5UKkkVzUg","executionInfo":{"status":"ok","timestamp":1648816890880,"user_tz":-480,"elapsed":25,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9b4e2352-a230-458c-d559-b2d22e4cb603"},"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[8.2570e-04, 1.1181e-02, 7.6950e-04, 2.0617e-03, 2.5529e-02, 3.4316e-03,\n","         1.6988e-04, 1.3170e-04, 6.7027e-04],\n","        [2.3962e-03, 2.2656e-03, 4.2209e-03, 5.4329e-03, 9.4490e-02, 1.3184e-02,\n","         5.3729e-05, 8.1337e-05, 4.0281e-04],\n","        [9.3554e-02, 3.7613e-02, 1.2216e-01, 1.2142e-02, 3.3810e-01, 1.6481e-01,\n","         2.3211e-05, 1.2565e-04, 2.3094e-03],\n","        [3.6090e-03, 7.1548e-03, 8.7892e-04, 1.2997e-02, 9.5557e-02, 4.1069e-02,\n","         7.3982e-05, 1.0048e-04, 2.9299e-04],\n","        [2.8937e-01, 5.5662e-02, 2.7990e-03, 2.5894e-02, 6.5025e-02, 4.6800e-01,\n","         4.0391e-04, 6.5753e-04, 1.1078e-03],\n","        [1.6798e-01, 6.7868e-02, 1.2239e-02, 1.3434e-01, 3.2621e-01, 8.5109e-02,\n","         1.1458e-04, 1.2394e-04, 4.5320e-04],\n","        [4.4447e-01, 4.1660e-01, 9.9466e-01, 9.7425e-01, 7.3748e-01, 9.7888e-01,\n","         4.8269e-03, 2.4254e-02, 1.0784e-02],\n","        [5.5079e-02, 8.2447e-03, 9.2682e-03, 1.5477e-02, 3.7145e-02, 2.8280e-02,\n","         2.0556e-04, 1.7764e-04, 1.2817e-03],\n","        [3.3448e-03, 1.5950e-02, 1.4724e-03, 3.0791e-03, 5.2207e-02, 1.5048e-02,\n","         5.2622e-05, 5.7021e-05, 2.4032e-04],\n","        [1.9380e-02, 6.6618e-02, 4.6096e-02, 2.6099e-01, 8.7470e-01, 5.5992e-01,\n","         2.7419e-04, 2.4750e-04, 2.8380e-04]])"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","metadata":{"id":"UxdHDFu3oDRR","executionInfo":{"status":"ok","timestamp":1648816890880,"user_tz":-480,"elapsed":22,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c9c6c1f0-9a8a-43e4-ce2a-02d8296b8d2d"},"source":["true_labels[0:10]"],"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0, 0, 0, 0, 1, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n","       [1, 0, 0, 0, 0, 1, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n","       [0, 0, 1, 1, 1, 1, 0, 1, 0],\n","       [0, 0, 0, 1, 1, 0, 0, 0, 0],\n","       [1, 1, 0, 0, 1, 1, 0, 0, 0],\n","       [0, 0, 0, 1, 1, 1, 0, 0, 0]])"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["np.save(\"predictions.npy\", predictions)\n","np.save(\"final_predictions.npy\", final_predictions)\n","\n","#loaded_predictions = np.load(\"predictions.npy\")\n","loaded_predictions = np.load(\"final_predictions.npy\")\n","print(loaded_predictions)"],"metadata":{"id":"KyAKUkdV4r2l","executionInfo":{"status":"ok","timestamp":1648816890880,"user_tz":-480,"elapsed":19,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c4fbf80a-b905-46a7-8c9f-15b05acf5c7d"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["[[8.2570349e-04 1.1180657e-02 7.6949969e-04 ... 1.6988165e-04\n","  1.3170247e-04 6.7027356e-04]\n"," [2.3961826e-03 2.2656410e-03 4.2208754e-03 ... 5.3729156e-05\n","  8.1336693e-05 4.0280959e-04]\n"," [9.3554154e-02 3.7613433e-02 1.2215829e-01 ... 2.3210619e-05\n","  1.2565032e-04 2.3094313e-03]\n"," ...\n"," [3.2726324e-01 5.7539858e-02 8.0203619e-03 ... 2.6613282e-04\n","  9.3227507e-05 1.4681017e-04]\n"," [1.5967617e-02 6.9915831e-01 9.7631526e-01 ... 6.9684824e-03\n","  4.9613905e-03 9.3942722e-03]\n"," [7.5148675e-04 2.1860651e-03 2.3587628e-03 ... 1.8890333e-04\n","  1.8537592e-04 4.8506312e-04]]\n"]}]},{"cell_type":"code","source":["np.save(\"true_labels.npy\", true_labels)\n","\n","loaded_true_labels = np.load(\"true_labels.npy\")\n","print(loaded_true_labels)"],"metadata":{"id":"yu2F-COj4rq0","executionInfo":{"status":"ok","timestamp":1648816890881,"user_tz":-480,"elapsed":18,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ceb83c07-bf5f-4b0a-e801-c14c199c2ad6"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 1 1 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n"]}]},{"cell_type":"code","source":["#predictions = np.load(\"predictions.npy\")\n","predictions = np.load(\"final_predictions.npy\")\n","true_labels = np.load(\"true_labels.npy\")"],"metadata":{"id":"rLXoXnDZRJbH","executionInfo":{"status":"ok","timestamp":1648816890881,"user_tz":-480,"elapsed":16,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"id":"un388VMLoDOM","executionInfo":{"status":"ok","timestamp":1648816890881,"user_tz":-480,"elapsed":16,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"41e234e9-40c1-4ba6-d03d-3e02808a8ff4"},"source":["#flat-score\n","eval_accuracy = flat_accuracy(predictions, true_labels)\n","\n","# Report the final accuracy for this validation run.\n","print(\"  Accuracy 0: {0:.2f}\".format(eval_accuracy[0]))\n","print(\"  Accuracy 1: {0:.2f}\".format(eval_accuracy[1]))\n","print(\"  Accuracy 2: {0:.2f}\".format(eval_accuracy[2]))\n","print(\"  Accuracy 3: {0:.2f}\".format(eval_accuracy[3]))\n","print(\"  Accuracy 4: {0:.2f}\".format(eval_accuracy[4]))\n","print(\"  Accuracy 5: {0:.2f}\".format(eval_accuracy[5]))\n","print(\"  Accuracy 6: {0:.2f}\".format(eval_accuracy[6]))\n","print(\"  Accuracy 7: {0:.2f}\".format(eval_accuracy[7]))\n","print(\"  Accuracy 8: {0:.2f}\".format(eval_accuracy[8]))"],"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["  Accuracy 0: 0.62\n","  Accuracy 1: 0.52\n","  Accuracy 2: 0.58\n","  Accuracy 3: 0.42\n","  Accuracy 4: 0.70\n","  Accuracy 5: 0.46\n","  Accuracy 6: 0.00\n","  Accuracy 7: 0.50\n","  Accuracy 8: 0.35\n"]}]},{"cell_type":"markdown","source":["## 6. Threshold Calculation"],"metadata":{"id":"3fZRNO9pWRNk"}},{"cell_type":"code","source":["# Import module for data manipulation\n","import pandas as pd\n","# Import module for linear algebra\n","import numpy as np\n","# Import module for data simulation\n","from sklearn.datasets import make_classification     # Create a synthetic dataframe\n","from sklearn.linear_model import LogisticRegression  # Classification model\n","from sklearn.model_selection import train_test_split # Split the dataframe\n","from sklearn.metrics import roc_curve                # Calculate the ROC curve\n","from sklearn.metrics import precision_recall_curve   # Calculate the Precision-Recall curve\n","from sklearn.metrics import f1_score                 # Calculate the F-score\n","# Import module for data visualization\n","from plotnine import *\n","import plotnine"],"metadata":{"id":"Gqn_OT_CfSfY","executionInfo":{"status":"ok","timestamp":1648816891413,"user_tz":-480,"elapsed":546,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["thresh_f = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","thresh_roc = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"],"metadata":{"id":"eS6oh9v4WXlV","executionInfo":{"status":"ok","timestamp":1648816891413,"user_tz":-480,"elapsed":2,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["n = 9\n","for i in range(0, n):\n","  print('permission ',i)\n","\n","  predictions = np.load(\"final_predictions.npy\")\n","  true_labels = np.load(\"true_labels.npy\")\n","\n","  # Array for finding the optimal threshold\n","  thresholds = np.arange(0.0, 1.0, 0.0001)\n","  fscore = np.zeros(shape=(len(thresholds)))\n","  print('Length of sequence: {}'.format(len(thresholds)))\n","\n","  labels = true_labels[:, i]\n","  pred = predictions[:, i]\n","\n","  # Fit the model\n","  for index, elem in enumerate(thresholds):\n","    # Corrected probabilities\n","    y_pred_prob = (pred > elem).astype('int')\n","    # Calculate the f-score\n","    fscore[index] = f1_score(labels, y_pred_prob)\n","\n","  # Find the optimal threshold\n","  index = np.argmax(fscore)\n","  thresholdOpt = round(thresholds[index], ndigits = 4)\n","  fscoreOpt = round(fscore[index], ndigits = 4)\n","  thresh_f[i] = thresholdOpt\n","  print('Best Threshold: {} with F-Score: {}'.format(thresholdOpt, fscoreOpt))\n","\n","print(\"-------------------------------------\")\n","print(\"optimal threshold tuning for f-score\")\n","print(thresh_f)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TTL789HHbSEQ","executionInfo":{"status":"ok","timestamp":1648817053040,"user_tz":-480,"elapsed":161629,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}},"outputId":"65206383-bdf2-471b-e1c4-6c96a9ee484e"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["permission  0\n","Length of sequence: 10000\n","Best Threshold: 0.1332 with F-Score: 0.6765\n","permission  1\n","Length of sequence: 10000\n","Best Threshold: 0.2102 with F-Score: 0.5964\n","permission  2\n","Length of sequence: 10000\n","Best Threshold: 0.192 with F-Score: 0.5935\n","permission  3\n","Length of sequence: 10000\n","Best Threshold: 0.1352 with F-Score: 0.53\n","permission  4\n","Length of sequence: 10000\n","Best Threshold: 0.0686 with F-Score: 0.7945\n","permission  5\n","Length of sequence: 10000\n","Best Threshold: 0.1869 with F-Score: 0.52\n","permission  6\n","Length of sequence: 10000\n","Best Threshold: 0.2136 with F-Score: 0.1176\n","permission  7\n","Length of sequence: 10000\n","Best Threshold: 0.1924 with F-Score: 0.5\n","permission  8\n","Length of sequence: 10000\n","Best Threshold: 0.0684 with F-Score: 0.3743\n","-------------------------------------\n","optimal threshold tuning for f-score\n","[0.1332, 0.2102, 0.192, 0.1352, 0.0686, 0.1869, 0.2136, 0.1924, 0.0684]\n"]}]},{"cell_type":"code","source":["##for roc curve with g-mean\n","\n","n = 9\n","for i in range(0, n):\n","  print('permission ',i)\n","\n","  predictions = np.load(\"final_predictions.npy\")\n","  true_labels = np.load(\"true_labels.npy\")\n","\n","  labels = true_labels[:, i]\n","  pred = predictions[:, i]\n","\n","  # Create the ROC curve\n","  fpr, tpr, thresholds = roc_curve(labels, pred)\n","\n","  df_fpr_tpr = pd.DataFrame({'FPR':fpr, 'TPR':tpr, 'Threshold':thresholds})\n","\n","  # Calculate the G-mean\n","  gmean = np.sqrt(tpr * (1 - fpr))\n","\n","  # Find the optimal threshold\n","  index = np.argmax(gmean)\n","  thresholdOpt = round(thresholds[index], ndigits = 4)\n","  gmeanOpt = round(gmean[index], ndigits = 4)\n","  fprOpt = round(fpr[index], ndigits = 4)\n","  tprOpt = round(tpr[index], ndigits = 4)\n","\n","  thresh_roc[i] = thresholdOpt\n","  print('Best Threshold: {} with G-Mean: {}'.format(thresholdOpt, gmeanOpt))\n","  print('FPR: {}, TPR: {}'.format(fprOpt, tprOpt))\n","\n","print(\"-------------------------------------\")\n","print(\"ROC curve with G-mean threshold tuning\")\n","print(thresh_roc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k8hqRRBlhoA2","executionInfo":{"status":"ok","timestamp":1648817053040,"user_tz":-480,"elapsed":15,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}},"outputId":"2775bfc4-43d8-4c97-e539-f9c282f794d6"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["permission  0\n","Best Threshold: 0.06120000034570694 with G-Mean: 0.8417\n","FPR: 0.1377, TPR: 0.8215\n","permission  1\n","Best Threshold: 0.05299999937415123 with G-Mean: 0.7808\n","FPR: 0.1991, TPR: 0.7612\n","permission  2\n","Best Threshold: 0.024299999698996544 with G-Mean: 0.8273\n","FPR: 0.1449, TPR: 0.8005\n","permission  3\n","Best Threshold: 0.02449999935925007 with G-Mean: 0.8022\n","FPR: 0.2284, TPR: 0.834\n","permission  4\n","Best Threshold: 0.13580000400543213 with G-Mean: 0.785\n","FPR: 0.2165, TPR: 0.7864\n","permission  5\n","Best Threshold: 0.06549999862909317 with G-Mean: 0.7666\n","FPR: 0.218, TPR: 0.7515\n","permission  6\n","Best Threshold: 0.0008999999845400453 with G-Mean: 0.5589\n","FPR: 0.1409, TPR: 0.3636\n","permission  7\n","Best Threshold: 0.002199999988079071 with G-Mean: 0.8866\n","FPR: 0.0567, TPR: 0.8333\n","permission  8\n","Best Threshold: 0.003100000089034438 with G-Mean: 0.7705\n","FPR: 0.1383, TPR: 0.6889\n","-------------------------------------\n","ROC curve with G-mean threshold tuning\n","[0.0612, 0.053, 0.0243, 0.0245, 0.1358, 0.0655, 0.0009, 0.0022, 0.0031]\n"]}]},{"cell_type":"markdown","source":["## 7. Performance Score"],"metadata":{"id":"zw32F8bQWYx3"}},{"cell_type":"code","source":["#Fscore micro for different thresholds-"],"metadata":{"id":"qTNcFHFWW8Za"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#predictions = np.load(\"predictions.npy\")\n","predictions = np.load(\"final_predictions.npy\")\n","true_labels = np.load(\"true_labels.npy\")"],"metadata":{"id":"WZfjPXV4KURP","executionInfo":{"status":"ok","timestamp":1648817053041,"user_tz":-480,"elapsed":15,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["# Function to calculate the accuracy of our predictions vs labels\n","\n","import numpy as np\n","from sklearn.metrics import f1_score\n","\n","def f_at_1(preds, labels):\n","    #print('my_print_2')\n","    acc = [0, 0 ,0 ,0 ,0 ,0, 0, 0, 0]\n","    preds_th = preds\n","    \n","    preds_th[:, 0] = np.array(preds[:, 0]) >= thresh_f[0]\n","    preds_th[:, 1] = np.array(preds[:, 1]) >= thresh_f[1]\n","    preds_th[:, 2] = np.array(preds[:, 2]) >= thresh_f[2]\n","    preds_th[:, 3] = np.array(preds[:, 3]) >= thresh_f[3]\n","    preds_th[:, 4] = np.array(preds[:, 4]) >= thresh_f[4]\n","    preds_th[:, 5] = np.array(preds[:, 5]) >= thresh_f[5]\n","    preds_th[:, 6] = np.array(preds[:, 6]) >= thresh_f[6]\n","    preds_th[:, 7] = np.array(preds[:, 7]) >= thresh_f[7]\n","    preds_th[:, 8] = np.array(preds[:, 8]) >= thresh_f[8]\n","\n","   \n","    acc[0] = f1_score(labels[:, 0], preds_th[:, 0])\n","    acc[1] = f1_score(labels[:, 1], preds_th[:, 1])\n","    acc[2] = f1_score(labels[:, 2], preds_th[:, 2])\n","    acc[3] = f1_score(labels[:, 3], preds_th[:, 3])\n","    acc[4] = f1_score(labels[:, 4], preds_th[:, 4])\n","    acc[5] = f1_score(labels[:, 5], preds_th[:, 5])\n","    acc[6] = f1_score(labels[:, 6], preds_th[:, 6])\n","    acc[7] = f1_score(labels[:, 7], preds_th[:, 7])\n","    acc[8] = f1_score(labels[:, 8], preds_th[:, 8])\n","\n","   #f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n","\n","    #print(acc)\n","    return acc"],"metadata":{"id":"I5CdSjcgbB1n","executionInfo":{"status":"ok","timestamp":1648817053041,"user_tz":-480,"elapsed":15,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["eval_accuracy = f_at_1(predictions, true_labels)\n","\n","np.save(\"F1_CV5_N121k_Bert.npy\", eval_accuracy)\n","\n","# Report the final accuracy for this validation run.\n","print(\"  Camera    : {0:.4f}\".format(eval_accuracy[0]))\n","print(\"  Location  : {0:.4f}\".format(eval_accuracy[1]))\n","print(\"  Microphone: {0:.4f}\".format(eval_accuracy[2]))\n","print(\"  Contacts  : {0:.4f}\".format(eval_accuracy[3]))\n","print(\"  Storage   : {0:.4f}\".format(eval_accuracy[4]))\n","print(\"  Phone     : {0:.4f}\".format(eval_accuracy[5]))\n","print(\"  SMS       : {0:.4f}\".format(eval_accuracy[6]))\n","print(\"  Call_Log  : {0:.4f}\".format(eval_accuracy[7]))\n","print(\"  Calendar  : {0:.4f}\".format(eval_accuracy[8]))\n","\n","print(\"\")\n","avg_score = (np.sum(eval_accuracy, dtype = np.float32)) / 9\n","print(\"  Average F1 score: {0:.4f}\".format(avg_score))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2871c333-b878-44fb-cbdb-d6095a6b9cd4","executionInfo":{"status":"ok","timestamp":1648817053041,"user_tz":-480,"elapsed":14,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}},"id":"POz8vLKWbB1n"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["  Camera    : 0.6765\n","  Location  : 0.5964\n","  Microphone: 0.5935\n","  Contacts  : 0.5300\n","  Storage   : 0.7945\n","  Phone     : 0.5200\n","  SMS       : 0.1176\n","  Call_Log  : 0.5000\n","  Calendar  : 0.3743\n","\n","  Average F1 score: 0.5225\n"]}]},{"cell_type":"code","source":["#Fscore micro for different thresholds-"],"metadata":{"id":"BlwUzJfFbB1o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#predictions = np.load(\"predictions.npy\")\n","predictions = np.load(\"final_predictions.npy\")\n","true_labels = np.load(\"true_labels.npy\")"],"metadata":{"id":"YgKAxM5TbB1o","executionInfo":{"status":"ok","timestamp":1648817101597,"user_tz":-480,"elapsed":392,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["# Function to calculate the accuracy of our predictions vs labels\n","\n","import numpy as np\n","from sklearn.metrics import f1_score\n","\n","def f1micro_accuracy(preds, labels):\n","    #print('my_print_2')\n","    acc = [0, 0 ,0 ,0 ,0 ,0, 0, 0, 0]\n","    preds_th = preds\n","    \n","    preds_th[:, 0] = np.array(preds[:, 0]) >= thresh_f[0]\n","    preds_th[:, 1] = np.array(preds[:, 1]) >= thresh_f[1]\n","    preds_th[:, 2] = np.array(preds[:, 2]) >= thresh_f[2]\n","    preds_th[:, 3] = np.array(preds[:, 3]) >= thresh_f[3]\n","    preds_th[:, 4] = np.array(preds[:, 4]) >= thresh_f[4]\n","    preds_th[:, 5] = np.array(preds[:, 5]) >= thresh_f[5]\n","    preds_th[:, 6] = np.array(preds[:, 6]) >= thresh_f[6]\n","    preds_th[:, 7] = np.array(preds[:, 7]) >= thresh_f[7]\n","    preds_th[:, 8] = np.array(preds[:, 8]) >= thresh_f[8]\n","\n","    acc[0] = f1_score(labels[:, 0], preds_th[:, 0], average='micro')\n","    acc[1] = f1_score(labels[:, 1], preds_th[:, 1], average='micro')\n","    acc[2] = f1_score(labels[:, 2], preds_th[:, 2], average='micro')\n","    acc[3] = f1_score(labels[:, 3], preds_th[:, 3], average='micro')\n","    acc[4] = f1_score(labels[:, 4], preds_th[:, 4], average='micro')\n","    acc[5] = f1_score(labels[:, 5], preds_th[:, 5], average='micro')\n","    acc[6] = f1_score(labels[:, 6], preds_th[:, 6], average='micro')\n","    acc[7] = f1_score(labels[:, 7], preds_th[:, 7], average='micro')\n","    acc[8] = f1_score(labels[:, 8], preds_th[:, 8], average='micro')\n","    \n","   #f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n","\n","    #print(acc)\n","    return acc"],"metadata":{"id":"dsxmYyCebB1o","executionInfo":{"status":"ok","timestamp":1648817105571,"user_tz":-480,"elapsed":802,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["eval_accuracy = f1micro_accuracy(predictions, true_labels)\n","\n","np.save(\"F1Mic_CV5_N121k_Bert.npy\", eval_accuracy)\n","\n","# Report the final accuracy for this validation run.\n","\n","print(\"  Camera    : {0:.4f}\".format(eval_accuracy[0]))\n","print(\"  Location  : {0:.4f}\".format(eval_accuracy[1]))\n","print(\"  Microphone: {0:.4f}\".format(eval_accuracy[2]))\n","print(\"  Contacts  : {0:.4f}\".format(eval_accuracy[3]))\n","print(\"  Storage   : {0:.4f}\".format(eval_accuracy[4]))\n","print(\"  Phone     : {0:.4f}\".format(eval_accuracy[5]))\n","print(\"  SMS       : {0:.4f}\".format(eval_accuracy[6]))\n","print(\"  Call_Log  : {0:.4f}\".format(eval_accuracy[7]))\n","print(\"  Calendar  : {0:.4f}\".format(eval_accuracy[8]))\n","\n","print(\"\")\n","\n","avg_score = (np.sum(eval_accuracy, dtype = np.float32)) / 9\n","print(\"  Average F1 (micro) score: {0:.4f}\".format(avg_score))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7a8395b5-b381-48a6-84cb-b81582725d4c","executionInfo":{"status":"ok","timestamp":1648817111653,"user_tz":-480,"elapsed":411,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}},"id":"Go__GPzIbB1o"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["  Camera    : 0.8856\n","  Location  : 0.8791\n","  Microphone: 0.9191\n","  Contacts  : 0.8830\n","  Storage   : 0.7690\n","  Phone     : 0.8519\n","  SMS       : 0.9968\n","  Call_Log  : 0.9991\n","  Calendar  : 0.9747\n","\n","  Average F1 (micro) score: 0.9065\n"]}]},{"cell_type":"code","source":["#roc-auc score for different thresholds-"],"metadata":{"id":"aX6gLZ6nfIF9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","#predictions = np.load(\"predictions.npy\")\n","predictions = np.load(\"final_predictions.npy\")\n","true_labels = np.load(\"true_labels.npy\")"],"metadata":{"id":"ZBGJm1_RfIDJ","executionInfo":{"status":"ok","timestamp":1648817116155,"user_tz":-480,"elapsed":444,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["# Function to calculate the accuracy of our predictions vs labels\n","\n","import numpy as np\n","from sklearn.metrics import roc_auc_score\n","\n","def roc_auc(preds, labels):\n","    #print('my_print_2')\n","    acc = [0, 0 ,0 ,0 ,0 ,0, 0, 0, 0]\n","    preds_th = preds\n","    \n","    preds_th[:, 0] = np.array(preds[:, 0]) >= thresh_roc[0]\n","    preds_th[:, 1] = np.array(preds[:, 1]) >= thresh_roc[1]\n","    preds_th[:, 2] = np.array(preds[:, 2]) >= thresh_roc[2]\n","    preds_th[:, 3] = np.array(preds[:, 3]) >= thresh_roc[3]\n","    preds_th[:, 4] = np.array(preds[:, 4]) >= thresh_roc[4]\n","    preds_th[:, 5] = np.array(preds[:, 5]) >= thresh_roc[5]\n","    preds_th[:, 6] = np.array(preds[:, 6]) >= thresh_roc[6]\n","    preds_th[:, 7] = np.array(preds[:, 7]) >= thresh_roc[7]\n","    preds_th[:, 8] = np.array(preds[:, 8]) >= thresh_roc[8]\n","\n","\n","    acc[0] = roc_auc_score(labels[:, 0], preds_th[:, 0])\n","    acc[1] = roc_auc_score(labels[:, 1], preds_th[:, 1])\n","    acc[2] = roc_auc_score(labels[:, 2], preds_th[:, 2])\n","    acc[3] = roc_auc_score(labels[:, 3], preds_th[:, 3])\n","    acc[4] = roc_auc_score(labels[:, 4], preds_th[:, 4])\n","    acc[5] = roc_auc_score(labels[:, 5], preds_th[:, 5])\n","    acc[6] = roc_auc_score(labels[:, 6], preds_th[:, 6])\n","    acc[7] = roc_auc_score(labels[:, 7], preds_th[:, 7])\n","    acc[8] = roc_auc_score(labels[:, 8], preds_th[:, 8])\n","   \n","\n","    #print(acc)\n","    return acc"],"metadata":{"id":"pUkLexfpfirM","executionInfo":{"status":"ok","timestamp":1648817116571,"user_tz":-480,"elapsed":1,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","source":["#roc-auc score\n","\n","eval_accuracy = roc_auc(predictions, true_labels)\n","\n","np.save(\"ROC_CV5_N121k_Bert.npy\", eval_accuracy)\n","\n","# Report the final accuracy for this validation run.\n","\n","print(\"  Camera    : {0:.4f}\".format(eval_accuracy[0]))\n","print(\"  Location  : {0:.4f}\".format(eval_accuracy[1]))\n","print(\"  Microphone: {0:.4f}\".format(eval_accuracy[2]))\n","print(\"  Contacts  : {0:.4f}\".format(eval_accuracy[3]))\n","print(\"  Storage   : {0:.4f}\".format(eval_accuracy[4]))\n","print(\"  Phone     : {0:.4f}\".format(eval_accuracy[5]))\n","print(\"  SMS       : {0:.4f}\".format(eval_accuracy[6]))\n","print(\"  Call_Log  : {0:.4f}\".format(eval_accuracy[7]))\n","print(\"  Calendar  : {0:.4f}\".format(eval_accuracy[8]))\n","\n","print(\"\")\n","\n","avg_score = (np.sum(eval_accuracy, dtype = np.float32)) / 9\n","print(\"  Average ROC_AUC score: {0:.4f}\".format(avg_score))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"719NmYgXfH-C","outputId":"31e14297-dbdc-4681-8ba8-38629955de6a","executionInfo":{"status":"ok","timestamp":1648817129903,"user_tz":-480,"elapsed":403,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["  Camera    : 0.8412\n","  Location  : 0.7803\n","  Microphone: 0.8278\n","  Contacts  : 0.8028\n","  Storage   : 0.7850\n","  Phone     : 0.7660\n","  SMS       : 0.6079\n","  Call_Log  : 0.8054\n","  Calendar  : 0.7744\n","\n","  Average ROC_AUC score: 0.7768\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"-avk-bxXbBJI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"MZ9tYsF1uCaa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ACNET Performance"],"metadata":{"id":"Z43u183AavAn"}},{"cell_type":"markdown","source":["#### a) Data Preparation"],"metadata":{"id":"w1kC0WBMa059"}},{"cell_type":"code","execution_count":62,"metadata":{"id":"dv_2bp8k8oRR","executionInfo":{"status":"ok","timestamp":1648817138759,"user_tz":-480,"elapsed":1,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"outputs":[],"source":["## drive path\n","acnet_path = \"/content/drive/MyDrive/MetadataCSV/acnet_dataset_preprocess.csv\""]},{"cell_type":"code","execution_count":63,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":514,"status":"ok","timestamp":1648817139870,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"},"user_tz":-480},"id":"i3iH5EAk8oRZ","outputId":"71c83420-3ef0-48e7-f4a0-8e1d27befc01"},"outputs":[{"output_type":"stream","name":"stdout","text":["(1417, 14)\n"]}],"source":["df_acnet = pd.read_csv(acnet_path) \n","print(df_acnet.shape)"]},{"cell_type":"code","execution_count":64,"metadata":{"id":"F4BL9oX9GzgZ","executionInfo":{"status":"ok","timestamp":1648817140272,"user_tz":-480,"elapsed":2,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"outputs":[],"source":["df_acnet = df_acnet.dropna(subset=['Clean_Description'])"]},{"cell_type":"code","execution_count":65,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":250},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1648817140732,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"},"user_tz":-480},"id":"ASCqceOlDkY6","outputId":"56824af0-3d67-4284-eb42-a4d49cc5d3f0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   app_id                                        description  Storage  \\\n","0       0  ROOT is REQUIRED for automatic synchronization...        1   \n","1       1  This app delivers short scriptures containing ...        0   \n","2       2  This game is surprisingly simple and very addi...        0   \n","3       3  It is an online RPG game based on LBS location...        0   \n","4       4  Christmas is in the air. Get yourself in the h...        0   \n","\n","   Contacts  Location  Camera  Microphone  SMS  Call_Log  Phone  Calendar  \\\n","0         0         1       0           0    0         0      0         0   \n","1         0         0       0           0    1         0      0         0   \n","2         0         0       0           0    0         0      0         0   \n","3         0         1       0           0    0         0      0         0   \n","4         1         0       0           0    0         0      0         0   \n","\n","   Settings  Tasks                                  Clean_Description  \n","0         0      0  root is required for automatic synchronization...  \n","1         0      0  this app delivers short scriptures containing ...  \n","2         0      0  this game is surprisingly simple and very addi...  \n","3         0      0  it is an online rpg game based on lbs location...  \n","4         1      1  christmas is in the air. get yourself in the h...  "],"text/html":["\n","  <div id=\"df-f2ec2923-710f-4597-94bd-426d16fd16a5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>app_id</th>\n","      <th>description</th>\n","      <th>Storage</th>\n","      <th>Contacts</th>\n","      <th>Location</th>\n","      <th>Camera</th>\n","      <th>Microphone</th>\n","      <th>SMS</th>\n","      <th>Call_Log</th>\n","      <th>Phone</th>\n","      <th>Calendar</th>\n","      <th>Settings</th>\n","      <th>Tasks</th>\n","      <th>Clean_Description</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>ROOT is REQUIRED for automatic synchronization...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>root is required for automatic synchronization...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>This app delivers short scriptures containing ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>this app delivers short scriptures containing ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>This game is surprisingly simple and very addi...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>this game is surprisingly simple and very addi...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>It is an online RPG game based on LBS location...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>it is an online rpg game based on lbs location...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Christmas is in the air. Get yourself in the h...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>christmas is in the air. get yourself in the h...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2ec2923-710f-4597-94bd-426d16fd16a5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f2ec2923-710f-4597-94bd-426d16fd16a5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f2ec2923-710f-4597-94bd-426d16fd16a5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":65}],"source":["df_acnet.head()"]},{"cell_type":"code","source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","acnet_input_ids = []\n","\n","# For every sentence...\n","for sent in df_acnet.Clean_Description:\n","\n","    # Report the number of sentences.\n","    if((len(acnet_input_ids) % 20000) == 0):\n","        print(' Read {:,} comments'.format(len(acnet_input_ids)))\n","\n","    # `encode` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    encoded_sent = tokenizer.encode(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = MAX_LEN,       # Truncate all sentences.\n","                   )\n","    \n","    # Add the encoded sentence to the list\n","    acnet_input_ids.append(encoded_sent)\n","\n","print('DONE.')\n","print('')\n","print('{:>10,} acnet comments'.format(len(acnet_input_ids)))\n","\n","# Also retrieve the labels as a list.\n","\n","# Get the labels from the dataframe, and convert from booleans to ints\n","acnet_labels = df_acnet[target_list]\n","\n","#print('{:>10,} positive (contains attack)'.format(np.sum(test_labels)))\n","#print('{:>10,} negetive (not an attack)'.format(len(test_labels) - np.sum(test_labels)))\n","\n","# Pad our input tokens\n","acnet_input_ids = pad_sequences(acnet_input_ids, maxlen=MAX_LEN, \n","                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","# Create attention masks\n","acnet_attention_masks = []\n","\n","# Create a mask of 1s for each token followed by 0s for padding\n","for seq in acnet_input_ids:\n","  seq_mask = [float(i>0) for i in seq]\n","  acnet_attention_masks.append(seq_mask) \n","\n","##my_code_start\n","acnet_labels = acnet_labels.to_numpy()\n","##my_code_ends\n","\n","# Convert to tensors.\n","acnet_inputs = torch.tensor(acnet_input_ids)\n","acnet_masks = torch.tensor(acnet_attention_masks)\n","acnet_labels = torch.tensor(acnet_labels)\n","\n","# Set the batch size.  \n","batch_size = 32  \n","\n","# Create the DataLoader.\n","acnet_data = TensorDataset(acnet_inputs, acnet_masks, acnet_labels)\n","acnet_sampler = SequentialSampler(acnet_data)\n","acnet_dataloader = DataLoader(acnet_data, sampler=acnet_sampler, batch_size=batch_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3pBIW939a80T","executionInfo":{"status":"ok","timestamp":1648817154536,"user_tz":-480,"elapsed":10401,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}},"outputId":"66355341-730a-4d67-a0a4-4c08b3a73c28"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":[" Read 0 comments\n","DONE.\n","\n","     1,414 acnet comments\n"]}]},{"cell_type":"markdown","metadata":{"id":"lkRKM9JD6ip8"},"source":["#### b) Get Predictions"]},{"cell_type":"code","metadata":{"executionInfo":{"status":"ok","timestamp":1648817165981,"user_tz":-480,"elapsed":11450,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3ecbed5a-0ef4-46f7-ba39-af14650372e0","id":"uAbDdUKKd5kK"},"source":["# Prediction on acnet set\n","\n","print('Predicting labels for {:,} test sentences...'.format(len(acnet_inputs)))\n","\n","# Put model in evaluation mode\n","model.eval()\n","\n","# Tracking variables \n","predictions , true_labels = [], []\n","\n","# Measure elapsed time.\n","t0 = time.time()\n","\n","# Predict \n","for (step,batch) in enumerate(acnet_dataloader):\n","  # Add batch to GPU\n","  batch = tuple(t.to(device) for t in batch)\n","  \n","  #Progress update every 100 batches.\n","  if step % 100 == 0 and not step == 0:\n","      # Calculate elapsed time in minutes\n","      elapsed = format_time(time.time() - t0)\n","\n","      # Report progress.\n","      print('  Batch {:>5,} of {:>5,}. Elapsed: {:}.'.format(step, len(acnet_dataloader), elapsed))\n","\n","\n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask, b_labels = batch\n","  \n","  # Telling the model not to compute or store gradients, saving memory and \n","  # speeding up prediction\n","  with torch.no_grad():\n","      # Forward pass, calculate logit predictions\n","      outputs = model(b_input_ids, token_type_ids=None, \n","                      attention_mask=b_input_mask)\n","\n","  logits = outputs[0]\n","\n","  # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","  \n","  # Store predictions and true labels\n","  predictions.append(logits)\n","  true_labels.append(label_ids)\n","\n","print('    DONE.')"],"execution_count":67,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicting labels for 1,414 test sentences...\n","    DONE.\n"]}]},{"cell_type":"code","metadata":{"id":"2hxm3Frwd5kK","executionInfo":{"status":"ok","timestamp":1648817165981,"user_tz":-480,"elapsed":5,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"source":["# Combine the results across the batches.\n","predictions = np.concatenate(predictions, axis=0)\n","true_labels = np.concatenate(true_labels, axis=0)"],"execution_count":68,"outputs":[]},{"cell_type":"code","source":["tensor_predictions = torch.tensor(predictions)\n","final_predictions = torch.sigmoid(tensor_predictions)"],"metadata":{"id":"omfZ-cZbd5kK","executionInfo":{"status":"ok","timestamp":1648817165982,"user_tz":-480,"elapsed":6,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"execution_count":69,"outputs":[]},{"cell_type":"code","execution_count":70,"metadata":{"id":"N3blanrE7qRF","executionInfo":{"status":"ok","timestamp":1648817165982,"user_tz":-480,"elapsed":5,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"outputs":[],"source":["np.save(\"acnet_predictions.npy\", final_predictions)\n","loaded_predictions = np.load(\"acnet_predictions.npy\")\n","\n","np.save(\"acnet_labels.npy\", true_labels)\n","loaded_true_labels = np.load(\"acnet_labels.npy\")"]},{"cell_type":"markdown","metadata":{"id":"kH11XQNV6mu8"},"source":["#### c) Threshold Calculation"]},{"cell_type":"code","execution_count":71,"metadata":{"id":"gLt_n92b7K5D","executionInfo":{"status":"ok","timestamp":1648817165982,"user_tz":-480,"elapsed":5,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"outputs":[],"source":["thresh_f = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","thresh_roc = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"]},{"cell_type":"code","execution_count":72,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":87664,"status":"ok","timestamp":1648817253641,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"},"user_tz":-480},"id":"LTou7AXr7K5D","outputId":"48a5508c-b549-4cf6-e21e-eccc9fd10aad"},"outputs":[{"output_type":"stream","name":"stdout","text":["permission  0\n","Length of sequence: 10000\n","Best Threshold: 0.2559 with F-Score: 0.7752\n","permission  1\n","Length of sequence: 10000\n","Best Threshold: 0.2585 with F-Score: 0.7909\n","permission  2\n","Length of sequence: 10000\n","Best Threshold: 0.3623 with F-Score: 0.8738\n","permission  3\n","Length of sequence: 10000\n","Best Threshold: 0.1863 with F-Score: 0.803\n","permission  4\n","Length of sequence: 10000\n","Best Threshold: 0.0756 with F-Score: 0.646\n","permission  5\n","Length of sequence: 10000\n","Best Threshold: 0.3292 with F-Score: 0.577\n","permission  6\n","Length of sequence: 10000\n","Best Threshold: 0.2385 with F-Score: 0.9476\n","permission  7\n","Length of sequence: 10000\n","Best Threshold: 0.4551 with F-Score: 0.8473\n","permission  8\n","Length of sequence: 10000\n","Best Threshold: 0.7024 with F-Score: 0.9463\n","-------------------------------------\n","optimal threshold tuning for f-score\n","[0.2559, 0.2585, 0.3623, 0.1863, 0.0756, 0.3292, 0.2385, 0.4551, 0.7024]\n"]}],"source":["n = 9\n","for i in range(0, n):\n","  print('permission ',i)\n","\n","  predictions = np.load(\"acnet_predictions.npy\")\n","  true_labels = np.load(\"acnet_labels.npy\")\n","\n","  # Array for finding the optimal threshold\n","  thresholds = np.arange(0.0, 1.0, 0.0001)\n","  fscore = np.zeros(shape=(len(thresholds)))\n","  print('Length of sequence: {}'.format(len(thresholds)))\n","\n","  labels = true_labels[:, i]\n","  pred = predictions[:, i]\n","\n","  # Fit the model\n","  for index, elem in enumerate(thresholds):\n","    # Corrected probabilities\n","    y_pred_prob = (pred > elem).astype('int')\n","    # Calculate the f-score\n","    fscore[index] = f1_score(labels, y_pred_prob)\n","\n","  # Find the optimal threshold\n","  index = np.argmax(fscore)\n","  thresholdOpt = round(thresholds[index], ndigits = 4)\n","  fscoreOpt = round(fscore[index], ndigits = 4)\n","  thresh_f[i] = thresholdOpt\n","  print('Best Threshold: {} with F-Score: {}'.format(thresholdOpt, fscoreOpt))\n","\n","print(\"-------------------------------------\")\n","print(\"optimal threshold tuning for f-score\")\n","print(thresh_f)"]},{"cell_type":"code","execution_count":73,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1648817253641,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"},"user_tz":-480},"id":"n63_5Qrw7K5D","outputId":"47644819-e44f-48d6-9591-e949e5ab6383"},"outputs":[{"output_type":"stream","name":"stdout","text":["permission  0\n","Best Threshold: 0.13940000534057617 with G-Mean: 0.8887\n","FPR: 0.1046, TPR: 0.8821\n","permission  1\n","Best Threshold: 0.17100000381469727 with G-Mean: 0.874\n","FPR: 0.0964, TPR: 0.8454\n","permission  2\n","Best Threshold: 0.19910000264644623 with G-Mean: 0.9638\n","FPR: 0.0387, TPR: 0.9662\n","permission  3\n","Best Threshold: 0.13539999723434448 with G-Mean: 0.8689\n","FPR: 0.1491, TPR: 0.8874\n","permission  4\n","Best Threshold: 0.1453000009059906 with G-Mean: 0.6754\n","FPR: 0.3369, TPR: 0.688\n","permission  5\n","Best Threshold: 0.19689999520778656 with G-Mean: 0.8635\n","FPR: 0.15, TPR: 0.8772\n","permission  6\n","Best Threshold: 0.06499999761581421 with G-Mean: 0.9786\n","FPR: 0.0191, TPR: 0.9764\n","permission  7\n","Best Threshold: 0.2079000025987625 with G-Mean: 0.9444\n","FPR: 0.0379, TPR: 0.9271\n","permission  8\n","Best Threshold: 0.09960000216960907 with G-Mean: 0.9752\n","FPR: 0.0397, TPR: 0.9904\n","-------------------------------------\n","ROC curve with G-mean threshold tuning\n","[0.1394, 0.171, 0.1991, 0.1354, 0.1453, 0.1969, 0.065, 0.2079, 0.0996]\n"]}],"source":["##for roc curve with g-mean\n","\n","n = 9\n","for i in range(0, n):\n","  print('permission ',i)\n","\n","  predictions = np.load(\"acnet_predictions.npy\")\n","  true_labels = np.load(\"acnet_labels.npy\")\n","\n","  labels = true_labels[:, i]\n","  pred = predictions[:, i]\n","\n","  # Create the ROC curve\n","  fpr, tpr, thresholds = roc_curve(labels, pred)\n","\n","  df_fpr_tpr = pd.DataFrame({'FPR':fpr, 'TPR':tpr, 'Threshold':thresholds})\n","\n","  # Calculate the G-mean\n","  gmean = np.sqrt(tpr * (1 - fpr))\n","\n","  # Find the optimal threshold\n","  index = np.argmax(gmean)\n","  thresholdOpt = round(thresholds[index], ndigits = 4)\n","  gmeanOpt = round(gmean[index], ndigits = 4)\n","  fprOpt = round(fpr[index], ndigits = 4)\n","  tprOpt = round(tpr[index], ndigits = 4)\n","\n","  thresh_roc[i] = thresholdOpt\n","  print('Best Threshold: {} with G-Mean: {}'.format(thresholdOpt, gmeanOpt))\n","  print('FPR: {}, TPR: {}'.format(fprOpt, tprOpt))\n","\n","print(\"-------------------------------------\")\n","print(\"ROC curve with G-mean threshold tuning\")\n","print(thresh_roc)"]},{"cell_type":"markdown","metadata":{"id":"oaiD6RsY6roq"},"source":["#### d) Accuracy Score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xEBsf9h968fw"},"outputs":[],"source":["#Fscore micro for different thresholds-"]},{"cell_type":"code","execution_count":74,"metadata":{"id":"gT4jKNo468fx","executionInfo":{"status":"ok","timestamp":1648817253642,"user_tz":-480,"elapsed":12,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"outputs":[],"source":["#predictions = np.load(\"predictions.npy\")\n","predictions = np.load(\"acnet_predictions.npy\")\n","true_labels = np.load(\"acnet_labels.npy\")"]},{"cell_type":"code","execution_count":75,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1648817253642,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"},"user_tz":-480},"id":"LRI_xLqQ68fx","outputId":"b8d5215e-1a0f-41ec-ac0f-bb30bf9881f0"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Camera    : 0.7752\n","  Location  : 0.7909\n","  Microphone: 0.8738\n","  Contacts  : 0.8030\n","  Storage   : 0.6460\n","  Phone     : 0.5770\n","  SMS       : 0.9476\n","  Call_Log  : 0.8473\n","  Calendar  : 0.9463\n","\n","  Average F1 score: 0.8008\n"]}],"source":["eval_accuracy = f_at_1(predictions, true_labels)\n","\n","np.save(\"ACNET_F1_CV5_N121k_Bert.npy\", eval_accuracy)\n","\n","# Report the final accuracy for this validation run.\n","print(\"  Camera    : {0:.4f}\".format(eval_accuracy[0]))\n","print(\"  Location  : {0:.4f}\".format(eval_accuracy[1]))\n","print(\"  Microphone: {0:.4f}\".format(eval_accuracy[2]))\n","print(\"  Contacts  : {0:.4f}\".format(eval_accuracy[3]))\n","print(\"  Storage   : {0:.4f}\".format(eval_accuracy[4]))\n","print(\"  Phone     : {0:.4f}\".format(eval_accuracy[5]))\n","print(\"  SMS       : {0:.4f}\".format(eval_accuracy[6]))\n","print(\"  Call_Log  : {0:.4f}\".format(eval_accuracy[7]))\n","print(\"  Calendar  : {0:.4f}\".format(eval_accuracy[8]))\n","\n","print(\"\")\n","avg_score = (np.sum(eval_accuracy, dtype = np.float32)) / 9\n","print(\"  Average F1 score: {0:.4f}\".format(avg_score))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YWBjb1My68fx"},"outputs":[],"source":["#Fscore micro for different thresholds-"]},{"cell_type":"code","execution_count":76,"metadata":{"id":"3RtlqpbO68fx","executionInfo":{"status":"ok","timestamp":1648817253642,"user_tz":-480,"elapsed":9,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"outputs":[],"source":["#predictions = np.load(\"predictions.npy\")\n","predictions = np.load(\"acnet_predictions.npy\")\n","true_labels = np.load(\"acnet_labels.npy\")"]},{"cell_type":"code","execution_count":77,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1648817253643,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"},"user_tz":-480},"id":"NUg7jLhL68fy","outputId":"fa5b5c4a-9604-41c5-8632-26c6de8185cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Camera    : 0.9257\n","  Location  : 0.9088\n","  Microphone: 0.9724\n","  Contacts  : 0.8713\n","  Storage   : 0.6358\n","  Phone     : 0.9088\n","  SMS       : 0.9844\n","  Call_Log  : 0.9781\n","  Calendar  : 0.9922\n","\n","  Average F1 (micro) score: 0.9086\n"]}],"source":["eval_accuracy = f1micro_accuracy(predictions, true_labels)\n","\n","np.save(\"ACNET_F1Mic_CV5_N121k_Bert.npy\", eval_accuracy)\n","\n","# Report the final accuracy for this validation run.\n","\n","print(\"  Camera    : {0:.4f}\".format(eval_accuracy[0]))\n","print(\"  Location  : {0:.4f}\".format(eval_accuracy[1]))\n","print(\"  Microphone: {0:.4f}\".format(eval_accuracy[2]))\n","print(\"  Contacts  : {0:.4f}\".format(eval_accuracy[3]))\n","print(\"  Storage   : {0:.4f}\".format(eval_accuracy[4]))\n","print(\"  Phone     : {0:.4f}\".format(eval_accuracy[5]))\n","print(\"  SMS       : {0:.4f}\".format(eval_accuracy[6]))\n","print(\"  Call_Log  : {0:.4f}\".format(eval_accuracy[7]))\n","print(\"  Calendar  : {0:.4f}\".format(eval_accuracy[8]))\n","\n","print(\"\")\n","\n","avg_score = (np.sum(eval_accuracy, dtype = np.float32)) / 9\n","print(\"  Average F1 (micro) score: {0:.4f}\".format(avg_score))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QpP75J-h68fy"},"outputs":[],"source":["#roc-auc score for different thresholds-"]},{"cell_type":"code","execution_count":78,"metadata":{"id":"4lY2eMlQ68fy","executionInfo":{"status":"ok","timestamp":1648817253643,"user_tz":-480,"elapsed":7,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"}}},"outputs":[],"source":["import numpy as np\n","predictions = np.load(\"acnet_predictions.npy\")\n","true_labels = np.load(\"acnet_labels.npy\")"]},{"cell_type":"code","execution_count":79,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1648817253643,"user":{"displayName":"Shubhranshi Kapoor","userId":"08662237840245386492"},"user_tz":-480},"id":"k7FmDQWN68fy","outputId":"a0364717-cf36-479c-a915-529dc1ddb1a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Camera    : 0.8887\n","  Location  : 0.8745\n","  Microphone: 0.9638\n","  Contacts  : 0.8691\n","  Storage   : 0.6747\n","  Phone     : 0.8636\n","  SMS       : 0.9763\n","  Call_Log  : 0.9446\n","  Calendar  : 0.9705\n","\n","  Average ROC_AUC score: 0.8918\n"]}],"source":["#roc-auc score\n","\n","eval_accuracy = roc_auc(predictions, true_labels)\n","\n","np.save(\"ACNET_ROC_CV5_N121k_Bert.npy\", eval_accuracy)\n","\n","# Report the final accuracy for this validation run.\n","\n","print(\"  Camera    : {0:.4f}\".format(eval_accuracy[0]))\n","print(\"  Location  : {0:.4f}\".format(eval_accuracy[1]))\n","print(\"  Microphone: {0:.4f}\".format(eval_accuracy[2]))\n","print(\"  Contacts  : {0:.4f}\".format(eval_accuracy[3]))\n","print(\"  Storage   : {0:.4f}\".format(eval_accuracy[4]))\n","print(\"  Phone     : {0:.4f}\".format(eval_accuracy[5]))\n","print(\"  SMS       : {0:.4f}\".format(eval_accuracy[6]))\n","print(\"  Call_Log  : {0:.4f}\".format(eval_accuracy[7]))\n","print(\"  Calendar  : {0:.4f}\".format(eval_accuracy[8]))\n","\n","print(\"\")\n","\n","avg_score = (np.sum(eval_accuracy, dtype = np.float32)) / 9\n","print(\"  Average ROC_AUC score: {0:.4f}\".format(avg_score))"]},{"cell_type":"code","source":[""],"metadata":{"id":"-CLFeKlbwTWl"},"execution_count":null,"outputs":[]}]}